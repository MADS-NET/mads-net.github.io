[
  {
    "objectID": "guides/hdf5.html",
    "href": "guides/hdf5.html",
    "title": "HDF5 Logger",
    "section": "",
    "text": "By default, MADS enable capturing data produced in the network to a MongoDB database, one topic per table. This is very effective and has some advantages:\n\nconcurrency: it is possible to access the database while the data acquisition is still running, even from multiple clients\npersistence: the data is stored in a database, which is designed to handle large amounts of data and provide fast access; MongoDB datapases can also be replicated and sharded, which allows for high availability, scalability, and resiliency\nquerying: the data can be queried using the MongoDB query language, which is powerful and flexible; MongoDB aggregations can be defined as read-only tables, which can offload the processing from the client side and allow for complex data analysis\nvisualization: the data can be visualized using tools like MongoDB Compass, which provides a graphical interface to explore the data\n\nOn the other hand, for simpler tasks this can prove an overkill. Furthermore, if forces the user to learn the MongoDB query language, which is not always necessary. For these reasons, MADS provides a file-based logging system, which is simpler to use and does not require a database.\nSince data generted by MADS can have a complex and schema-free structure, a simple table-oriented logging is not sufficient, unless we would revert to multiple flat-files, which can turn too messy pretty quickly. For this reason, MADS uses the HDF5 format, which is a hierarchical data format that allows for storing complex data structures in a single file. HDF5 is widely used in scientific computing and data analysis, and it is supported by many libraries and tools.\nA common use for HDF5 is to store and retrieve data used for training machine learning models, given that the format has a good support within Python and other scripting languages (as GNU-R) used for data analysis."
  },
  {
    "objectID": "guides/hdf5.html#installation",
    "href": "guides/hdf5.html#installation",
    "title": "HDF5 Logger",
    "section": "Installation",
    "text": "Installation\nWhile the MongoDB logger agent (mads logger) comes pre-packaged with MADS, the HDF5 logger is a plugin that needs to be compiled and installed separately. To install it, run the following commands on the machine where you want the logs to be saved:\ngit clone --depth 1 https://github.com/MADS-Net/hdf5_plugin.git\ncd hdf5_plugin\ncmake -Bbuild -DCMAKE_INSTALL_PREFIX=$(mads -p)\ncmake --build build --target install\n\n\n\n\n\n\nBuilding the HDF5 Plugin\n\n\n\n\nFollow the instructions on https://github.com/MADS-Net/hdf5_plugin when building on Windows.\nSome CMake versions on Linux cannot compile successfully the project when a parallel build is enabled (-j option). If you encounter issues, try to build the project without parallelization, at least for the first build when the HDF5 library is compiled.\n\n\n\nConfirm that the plugin has been installed correctly by running:\nmads --plugins\nwhich shall also report the hdf5_writer.plugin entry."
  },
  {
    "objectID": "guides/hdf5.html#configuration",
    "href": "guides/hdf5.html#configuration",
    "title": "HDF5 Logger",
    "section": "Configuration",
    "text": "Configuration\nAs any agent, the plugin needs a proper entry in the MADS configuration file mads.ini. The relevant configuration parameters are:\n\nsub_topic: the array of topics that we want to log\nfilename: the full path name to the HDF5 file taht we want to create\nkeypaths: a dictionary of entries that we want to save (see below for details)\nkeypath_separator: the separator used to split the keypaths (default is .)\n\nLet’s consider an example. We want to log the data collected by an agent running the arduino_plugin, which produces the following JSON data structure on the topic arduino:\n{\n  \"data\": {\n    \"AI1\": 52,\n    \"AI2\": 44,\n    \"AI3\": 58,\n    \"AI4\": 45,\n    \"AI5\": 165,\n    \"DI1\": 1,\n    \"DI2\": 1,\n    \"DI3\": 1\n  },\n  \"hostname\": \"mads-agent.local\",\n  \"millis\": 150679,\n  \"timecode\": 39198.68,\n  \"timestamp\": {\n    \"$date\": \"2025-07-11T10:53:18.716+0200\"\n  }\n}\nThe HDF5 logger always saves the field timestamp, timecode, and hostname. Everything else is optional and must be specified on the INI file using keypaths. A keypath is a string representing the hierarchical path within the JSON structure. For example, the [\"data\"][\"AI1\"] field can be accessed using the keypath data.AI1, where the field separator is the dot (.) by default, and can be changed using the keypath_separator parameter.\nA valid INI section would then be:\n[hdf5_writer]\nsub_topic = [\"arduino\"]\nfilename = \"/path/to/test.h5\"\nkeypaths = {\"arduino\" = [\"data.AI1\", \"data.AI2\"]}\nkeypath_separator = \".\"\nWhereas, if we wanted to capture data from two different topics, we would do something like:\n[hdf5_writer]\nsub_topic = [\"arduino\", \"temp_sensor\"]\nfilename = \"/path/to/test.h5\"\nkeypaths = {\"arduino\" = [\"data.AI1\", \"data.AI2\"], \"temp_sensor\" = [\"data.Temperature\", \"data.Humidity\"]}\nkeypath_separator = \".\"\n\n\n\n\n\n\nWarning\n\n\n\nNote that the TOML standard used for mads.ini forbids newlines within a dictionary field, so that the keypaths field must be on a single line!\nAs an alternative, you can split the dictionary using sub-tables:\n[hdf5_writer]\nsub_topic = [\"arduino\", \"temp_sensor\"]\nfilename = \"/path/to/test.h5\"\nkeypath_separator = \".\"\n[hdf5_writer.keypaths]\narduino = [\"data.AI1\", \"data.AI2\"]\ntemp_sensor = [\"data.Temperature\", \"data.Humidity\"]"
  },
  {
    "objectID": "guides/hdf5.html#execution",
    "href": "guides/hdf5.html#execution",
    "title": "HDF5 Logger",
    "section": "Execution",
    "text": "Execution\nNow that the plugin is installed and configured, you can use it as a sink plugin:\nmads sink -s tcp://broker.host:9092 hdf5_writer.plugin\nOf course, if the plugin runs on the same broker machine, you can just use mads sink hdf5_writer.plugin. The initial output is something like:\nAgent: hdf5_writer\n  Settings file:    tcp://localhost:9092\n  Pub endpoint:     tcp://localhost:9090\n  Pub topic:        hdf5_writer\n  Sub endpoint:     tcp://localhost:9091\n  Sub topics:       arduino topic2 control\n  Compression:      enabled\n  Timecode FPS:     25\n  Timecode offset:  0 s\nSearching for installed plugin in the default location /Users/p4010/usr/local/lib\n  Plugin:           /usr/local/lib/hdf5_writer.plugin (loaded as hdf5_writer)\n  File name         /tmp/hdf5_plugin/test.h5\n  Keypath sep.      .\n  Keypaths          arduino.timecode, arduino.timestamp, arduino.hostname, arduino.data.AI1, arduino.data.AI2, temp_sensor.timecode, temp_sensor.timestamp, temp_sensor.hostname, temp_sensor.data.Temperature, temp_sensor.data.Humidity (total: 10)\nSink plugin started\nThe content of the HDF5 file can be quickly inspected using the HDFView GUI tool:\n\n\n\nAn overview of the captured data\n\n\nAs we see, within the HDF5 file data are collected into groups (folders), one for each topic, and datasets (tables), one for each keypath. The name of the dataset corresponds to the keypath:\n\nwhen the keypath produces a scalar, the dataset is a column vector (1-column table)\nwhen the keypath produces a vector, the dataset is a 2D table with one column per element of the vector\ntimecode and timestamp are collected as vectors (same length of any other table)\ntimecode is stored as a string according to ISO 8601 format, which is the default for MADS\n\nThe plugin CMake install command also installs three command-line tools to inspect the HDF5 file:\n\nh5ls: lists the contents of an HDF5 file\nh5watch: watches an HDF5 file for changes\nh5stat: displays statistics about an HDF5 file\n\nSo, for example, we can list the contents of the file using:\nh5ls -r /path/to/test.h5\nWhich produces an output like:\n/                        Group\n/arduino                 Group\n/arduino/data.AI1        Dataset {303/Inf}\n/arduino/data.AI2        Dataset {303/Inf}\n/arduino/hostname        Dataset {303/Inf}\n/arduino/timecode        Dataset {303/Inf}\n/arduino/timestamp       Dataset {303/Inf}\nWhere {303/Inf} indicates that the dataset has 303 elements and is not limited in size (i.e., it can grow indefinitely). The the h5stat command can be used to display statistics about the file, such as the number of datasets, groups, and attributes, as well as the size of the file.\nFinally, h5watch command can be used to monitor the file for changes, which is useful when the data acquisition is still running:\nh5watch /path/to/test.h5/arduino/data.AI1\n# will watch for changes untile CTRL-C"
  },
  {
    "objectID": "guides/worker.html",
    "href": "guides/worker.html",
    "title": "Parallel computing with MADS",
    "section": "",
    "text": "Sometimes, we want to explore a large parameter space, and run multiple time-demanding simulations over a grid of points in the parameter space. This is the case for example when we want to run a sensitivity analysis, or when we want to explore the effect of different parameters on the model output and perhaps find the optimal set of parameters for a given objective function.\nIf we have at hand a number of machines with multiple cores, we can effectively scale the problem by running each simulation on a different machine, or on a different core of the same machine. This is particularly useful when the simulations are independent and can be run in parallel."
  },
  {
    "objectID": "guides/worker.html#example-deployment",
    "href": "guides/worker.html#example-deployment",
    "title": "Parallel computing with MADS",
    "section": "Example deployment",
    "text": "Example deployment\nKubernetes deployments are YAML files that declare the configuration for each instance. a workable example is:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: worker\n  namespace: default\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      app: worker\n  template:\n    metadata:\n      labels:\n        app: worker\n    spec:\n      containers:\n        - name: worker\n          image: \"p4010/mads:latest\"\n          args: [\"worker\", \"-s\", \"tcp://198.19.249.3:9092\", \"-n\", \"test_worker_arm64\"]\n          resources:\n            limits:\n              cpu: 200m\n              memory: 500Mi\n            requests:\n              cpu: 100m\n              memory: 200Mi\n          ports:\n            - containerPort: 9091\n              name: zmq-in\n            - containerPort: 9092\n              name: zmq-ini\n            - containerPort: 9093\n              name: zmq-deal\nThis is defining each worker as an instance of the p4010/mads:latest Docker image, which is the official MADS image on Docker Hub. The args field specifies the command line arguments to pass to the worker agent, including the broker address and the worker name. In this case, we are assuming that Kubernetes runs on an ARM64 architecture, and the worker name is set to test_worker_arm64 (see OTA Plugins for more details on the worker name).\nWith this configuration saved as `manifest.yml, we can deploy the workers to the Kubernetes cluster with the following command:\nkubectl apply -f manifest.yml\nThis will start 5 replicas of the same worker instance, each loading the plugin OTA from the broker. If we want (and can) scale up the number of workers, we can do it transparently without disrupting any operation:\nkubectl scale deployments/worker --replicas=100\n\n\n\n\n\n\nWarning\n\n\n\nThe maximum number of replicas shall be less or equal to the total number of cores in the Kubernetes cluster. If you try to scale up beyond that, CPU resources will be further subdivided among the workers, and each worker will get less CPU time, which may lead to performance degradation.\n\n\nWhen we are done, we can scale down the number of workers to zero, or delete the deployment altogether:\nkubectl delete deployments worker"
  },
  {
    "objectID": "guides/worker.html#keeping-track-of-completed-tasks",
    "href": "guides/worker.html#keeping-track-of-completed-tasks",
    "title": "Parallel computing with MADS",
    "section": "Keeping track of completed tasks",
    "text": "Keeping track of completed tasks\nThe number of submitted and completed tasks can be easily monitored with a Python agent:\nimport json\nagent_type = \"sink\"\n\ndef setup():\n  print(\"[Python] Setting up sink...\")\n  print(\"[Python] Parameters: \" + json.dumps(params))\n  state[\"submitted\"] = 0\n  state[\"accepted\"] = 0\n \ndef deal_with_data():\n  if topic == \"dealer\":\n    state[\"submitted\"] += 1\n  if topic == \"test_worker\":\n    state[\"accepted\"] += 1\n  print(\"\\33[2K[Python] Submitted: \" + str(state[\"submitted\"]) + \", Accepted: \" + str(state[\"accepted\"]) + \", Pending: \" + str(state[\"submitted\"] - state[\"accepted\"]), end=\"\\r\")\nSave this as counter.py in the folder usr/local/scripts under the MADS prefix directory (given by mads -p), add the following section to the INI file:\n[counter]\nsub_topic = [\"dealer\", \"test_worker\"]\npython_module = \"counter\"\nthen run the agent with the command:\nmads python -n counter"
  },
  {
    "objectID": "guides/structure.html",
    "href": "guides/structure.html",
    "title": "Network structure",
    "section": "",
    "text": "The typical architecture of a MADS network can be represented as:\n\n\n\n\n\n\n\n\nMADS Network\n\n\n\np1\n\nPlugin 1\n\n\n\na1\n\nAgent 1\n(source)\n\n\n\np1-&gt;a1\n\n\n\n\nbroker\n\nbroker\n\n\n\na1-&gt;broker\n\n\n\n\n\np2\n\nPlugin 2\n\n\n\na2\n\nAgent 2\n(filter)\n\n\n\np2-&gt;a2\n\n\n\n\na2-&gt;broker\n\n\n\n\n\n\np3\n\nPlugin 3\n\n\n\na3\n\nAgent 3\n(sink)\n\n\n\np3-&gt;a3\n\n\n\n\na3-&gt;broker\n\n\n\n\n\na4\n\nMonolithic\nAgent (filter)\n\n\n\na4-&gt;broker\n\n\n\n\n\n\nmongo\n\n\nMongoDB\n\n\n\nlogger\n\nlogger\n\n\n\nbroker-&gt;logger\n\n\n\n\n\nlogger-&gt;mongo\n\n\nBSON\n\n\n\n\n\n\nFigure 1: MADS Network\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember that the above schematic represent processes, regardless the physical machine on which they are being executed.\nFor example, the whole network could run on a single workstation, or it could be conversely distributed over multiple devices connected to the same IP network, each device running a single process/node.\n\n\nIn the figure Figure 1, the solid lines represent a ZeroMQ connection over TCP/IP, which uses compressed JSON as a data encoding protocol. Compression is preformed with the snappy library. The dashed line, conversely, represents the proprietary MongoDB protocol, with data serialized as BSON (Binary-JSON).\n\n\nWhat is the broker purpose?\nThe broker solves the issue of knowing multiple network addresses when you have a number of devices participating to the same distributed system.\nWith the aid of the broker, any separate device partaking to the MADS network only needs to know a single hostname/IP address: that of the machine running the broker.\n\n\n\n\n\n\nWarning\n\n\n\nThere can only be a single broker per network.\n\n\nRunning the broker is quite simple:\nmads broker\n\n\n\nAgents can be:\n\nmonolithic: implemented as a single executable inheriting the Mads::Agent C++ class.\nplug-in: a single executable that on runtime loads a proper plug-in (i.e. a dynamically loaded library)\n\nRegardless the type, agent can have three different behaviors:\n\nsource: they provide information to the network (e.g. by reading sensors)\nfilter: they operate and transform received information\nsink: they consume information received from the network (e.g. to store or visualize)\n\nThe MADS installer provides three general purpose agents, aptly named source, filter, and sink, that are designe do load proper plugins. The command mads plugin can be used to generate a suitable template for a new plugin to be developed.\n\n\n\nAt the bare minimum, a MADS network requires:\n\nthe broker\nthe MongoDB database\nthe logger agent\n\nThe MADS installers provide broker and logger, but MongoDB must be installed separatedly. The easiest route is to it via Docker.\nIdeally, broker, logger and database should run on a single machine, having enough resources to store the data flow on the database, while agents can be distributed over multiple device.\n\n\n\n\n\n\nNote\n\n\n\nAccording to our testing, Linux is the best choice for running MADS broker and logger in terms of performance.\n\n\nAny other agent can be run on the same machine or on a separate machine. In the latter case, it must be started with the -s option stating the broker address, e.g.: -s tcp://&lt;hostname&gt;:9092, where &lt;hostname&gt; shall be replaced with the proper host name, if available, or with the machine IP address. This is the only address that any agent needs to know in order to connect to the MADS network.\nTo help you find out the proper address, you can use the -n list broker option:\n&gt; mads broker -n list\nAvailable network adapters:\n[       lo0] - 127.0.0.1\n[       en0] - 192.168.1.220\n[ bridge100] - 198.19.249.3\nThis shows that the host has three network interfaces. The public one is probably en0 (your names may vary). Now quit the broker and relaunch it as:\n&gt; mads broker -n en0\nReading settings from /Users/p4010/usr/local/etc/mads.ini [broker]\nUsing network interface en0\nBinding broker frontend (XSUB) at tcp://*:9090\nBinding broker backend (XPUB) at tcp://*:9091\nBinding broker shared settings (REP) at tcp://*:9092\nTimecode FPS: 25\nSettings are provided via tcp://192.168.1.220:9092\nCTRL-C to immediate exit\nType P to pause, R to resume, I for information, Q to clean quit, X to restart and reload settings\nLook at the line Settings are provided via tcp://192.168.1.220:9092: that is the address that you must use to start any agent in the network, e.g.:\nmads feedback -s tcp://192.168.1.220:9092\n\n\n\n\n\n\nImportant\n\n\n\nThe -n command line option has no effect on how the broker operates. Its only purpose is to help you find out the proper address to use when starting agents that run on different machines or devices."
  },
  {
    "objectID": "guides/structure.html#the-broker",
    "href": "guides/structure.html#the-broker",
    "title": "Network structure",
    "section": "",
    "text": "What is the broker purpose?\nThe broker solves the issue of knowing multiple network addresses when you have a number of devices participating to the same distributed system.\nWith the aid of the broker, any separate device partaking to the MADS network only needs to know a single hostname/IP address: that of the machine running the broker.\n\n\n\n\n\n\nWarning\n\n\n\nThere can only be a single broker per network.\n\n\nRunning the broker is quite simple:\nmads broker"
  },
  {
    "objectID": "guides/structure.html#the-agents",
    "href": "guides/structure.html#the-agents",
    "title": "Network structure",
    "section": "",
    "text": "Agents can be:\n\nmonolithic: implemented as a single executable inheriting the Mads::Agent C++ class.\nplug-in: a single executable that on runtime loads a proper plug-in (i.e. a dynamically loaded library)\n\nRegardless the type, agent can have three different behaviors:\n\nsource: they provide information to the network (e.g. by reading sensors)\nfilter: they operate and transform received information\nsink: they consume information received from the network (e.g. to store or visualize)\n\nThe MADS installer provides three general purpose agents, aptly named source, filter, and sink, that are designe do load proper plugins. The command mads plugin can be used to generate a suitable template for a new plugin to be developed."
  },
  {
    "objectID": "guides/structure.html#network-layout",
    "href": "guides/structure.html#network-layout",
    "title": "Network structure",
    "section": "",
    "text": "At the bare minimum, a MADS network requires:\n\nthe broker\nthe MongoDB database\nthe logger agent\n\nThe MADS installers provide broker and logger, but MongoDB must be installed separatedly. The easiest route is to it via Docker.\nIdeally, broker, logger and database should run on a single machine, having enough resources to store the data flow on the database, while agents can be distributed over multiple device.\n\n\n\n\n\n\nNote\n\n\n\nAccording to our testing, Linux is the best choice for running MADS broker and logger in terms of performance.\n\n\nAny other agent can be run on the same machine or on a separate machine. In the latter case, it must be started with the -s option stating the broker address, e.g.: -s tcp://&lt;hostname&gt;:9092, where &lt;hostname&gt; shall be replaced with the proper host name, if available, or with the machine IP address. This is the only address that any agent needs to know in order to connect to the MADS network.\nTo help you find out the proper address, you can use the -n list broker option:\n&gt; mads broker -n list\nAvailable network adapters:\n[       lo0] - 127.0.0.1\n[       en0] - 192.168.1.220\n[ bridge100] - 198.19.249.3\nThis shows that the host has three network interfaces. The public one is probably en0 (your names may vary). Now quit the broker and relaunch it as:\n&gt; mads broker -n en0\nReading settings from /Users/p4010/usr/local/etc/mads.ini [broker]\nUsing network interface en0\nBinding broker frontend (XSUB) at tcp://*:9090\nBinding broker backend (XPUB) at tcp://*:9091\nBinding broker shared settings (REP) at tcp://*:9092\nTimecode FPS: 25\nSettings are provided via tcp://192.168.1.220:9092\nCTRL-C to immediate exit\nType P to pause, R to resume, I for information, Q to clean quit, X to restart and reload settings\nLook at the line Settings are provided via tcp://192.168.1.220:9092: that is the address that you must use to start any agent in the network, e.g.:\nmads feedback -s tcp://192.168.1.220:9092\n\n\n\n\n\n\nImportant\n\n\n\nThe -n command line option has no effect on how the broker operates. Its only purpose is to help you find out the proper address to use when starting agents that run on different machines or devices."
  },
  {
    "objectID": "guides/zeroconf.html",
    "href": "guides/zeroconf.html",
    "title": "ZeroConf (aka Avahi) network discovery",
    "section": "",
    "text": "Using IP addresses for accessing other machines is bad practice, for The IP address of a given machine can change unexpectedly — for example, because it has been assigned by a DHCP server from a dynamic pool of available IPs.\nMuch more preferable is to use hostnames, that map to IP addresses dynamically. On the other hand, This requires a DNS server properly configured and updated.\nZeroConf comes to the rescue: it is an open protocol where all nodes on the same network advertise their services (ports) and host names by broadcasting, and by sharing the same, default local domain: .local.\nThe name ZeroConf is a bit misleading, for actually there is a configuration step, although it’s minimal and simple. The configuration, additionally, is node local, decentralized, and there is no need for any central server."
  },
  {
    "objectID": "guides/zeroconf.html#install-the-needed-packages",
    "href": "guides/zeroconf.html#install-the-needed-packages",
    "title": "ZeroConf (aka Avahi) network discovery",
    "section": "Install the needed packages",
    "text": "Install the needed packages\nsudo apt update && sudo apt install avahi-utils avahi-daemon openssh-server"
  },
  {
    "objectID": "guides/zeroconf.html#configure-the-service",
    "href": "guides/zeroconf.html#configure-the-service",
    "title": "ZeroConf (aka Avahi) network discovery",
    "section": "Configure the service",
    "text": "Configure the service\nCreate a file named /stc/avahi/services/ssh.service with the following content:\n&lt;!-- See avahi.service(5) for more information about this configuration file --&gt;\n\n&lt;service-group&gt;\n\n  &lt;name replace-wildcards=\"yes\"&gt;%h&lt;/name&gt;\n\n  &lt;service&gt;\n    &lt;type&gt;_ssh._tcp&lt;/type&gt;\n    &lt;port&gt;22&lt;/port&gt;\n  &lt;/service&gt;\n\n&lt;/service-group&gt;\nThis is making the host accessible as %h.local, where %h is a wildcard for the current hostname, and also advertising the ssh servoice on TCP port 22.\nThe list of services advertised on the local network can be obtained with:\navahi-browse -a"
  },
  {
    "objectID": "guides/zeroconf.html#apply-the-changes",
    "href": "guides/zeroconf.html#apply-the-changes",
    "title": "ZeroConf (aka Avahi) network discovery",
    "section": "Apply the changes",
    "text": "Apply the changes\nRemember to enable and start the service:\nsudo systemctl enable avahi-daemon\nsudo systemctl start avahi-daemon\nNow you can use &lt;hostname&gt;.local in place of its address: for example, when launching MADS agents, supposing the the broker is running on a device with hostname set to mads-broker, you can simply do:\nmads source -s tcp://mads-broker.local:9092 my_plugin.plugin"
  },
  {
    "objectID": "guides/install.html",
    "href": "guides/install.html",
    "title": "Installing MADS",
    "section": "",
    "text": "The installers are provided for:\n\nMacOS, as a universal binary (Intel and Apple Silicon)\nLinux, two different deb packages for X86 and aarm64 architectures; the latter also works for Raspberry Pi OS (Raspbian)\nWindows, as an exe installer (tested on Windows 10 and 11)\n\n\n\n\n\n\n\nImportant\n\n\n\nAlways get the latest MADS installer on: git.new/MADS\n\n\n\n\n\nSuppose that you downloaded the installer mads-&lt;version&gt;-Darwin-universal.sh (where &lt;version&gt; is the version number, e.g. 1.3.3). The installer takes the following arguments:\n./mads-1.3.3-Darwin-universal.sh --help\nUsage: packages/mads-1.3.3-Darwin-universal.sh [options]\nOptions: [defaults in brackets after descriptions]\n  --help            print this message\n  --version         print cmake installer version\n  --prefix=dir      directory in which to install\n  --include-subdir  include the mads-1.3.3-Darwin-universal subdirectory\n  --exclude-subdir  exclude the mads-1.3.3-Darwin-universal subdirectory\n  --skip-license    accept license\nIf you run it with no arguments, it will install MADS in the /usr/local/ directory (need sudo) and ask for accepting the license. If you (as me) prefer to keep it in your home directory, you can run:\n./mads-1.3.3-Darwin-universal.sh --prefix=${HOME} --skip-license    \nwhich will install in ${HOME}/usr/local and automatically accept license. Then, you want to add ${HOME}/usr/local/bin to your search path: add the following line to your .zshrc or .bashrc file:\nexport PATH=${HOME}/usr/local/bin:$PATH\nFinally, restart your terminal and check that MADS is correctly installed by running:\nmads --version\n\n\nUnless we’re talking of very specific use cases, you probably want to compile your own plugins. For that, you need the Apple Developer Tools installed, together with CMake and Git.\n\n\n\n\nOn git.new/MADS you find two deb packages:\n\nmads-&lt;version&gt;-Linux-x86_64.deb for Intel architectures\nmads-&lt;version&gt;-Linux-aarch64.deb for ARM architectures (e.g. Raspberry Pi)\n\nInstalling is as simple as:\nexport MV=1.3.3  # or the latest version\nwget https://github.com/pbosetti/MADS/releases/download/v${MV}/mads-${MV}-Linux-aarch64.deb\nsudo dpkg -i mads-${MV}-Linux-aarch64.deb\nrm mads-${MV}-Linux-aarch64.deb\n\n\n\n\n\n\nNote\n\n\n\nIf you run native Linux virtual machines on MacOS with Apple Silicon chips, as for example by using OrbStack, you need to install the aarch64 version of MADS within the VM. In other words, the same binaries work on Raspberry Pi OS (Raspbian) and on a Linux native VM running on Apple Silicon.\n\n\n\n\nUnless we’re talking of very specific use cases, you probably want to compile your own plugins. For that, you need the followings:\nsudo apt update\nsudo apt install build-essential cmake git clang\nIn addition, install any other library you plan to use in the development.\n\n\n\n\nThe Windows installer is a standard graphical exe installer. Download it from git.new/MADS and run it.\nThe installer installs MADS in C:\\Program Files\\MADS, The installer will also add the MADS bin directory to your search path.\n\n\nUnless we’re talking of very specific use cases, you probably want to compile your own plugins. For that, you need the Visual Studio 17 (Community Edition is fine) with the C++ development tools, together with CMake and Git."
  },
  {
    "objectID": "guides/install.html#getting-the-installers",
    "href": "guides/install.html#getting-the-installers",
    "title": "Installing MADS",
    "section": "",
    "text": "The installers are provided for:\n\nMacOS, as a universal binary (Intel and Apple Silicon)\nLinux, two different deb packages for X86 and aarm64 architectures; the latter also works for Raspberry Pi OS (Raspbian)\nWindows, as an exe installer (tested on Windows 10 and 11)\n\n\n\n\n\n\n\nImportant\n\n\n\nAlways get the latest MADS installer on: git.new/MADS"
  },
  {
    "objectID": "guides/install.html#installing-on-macos",
    "href": "guides/install.html#installing-on-macos",
    "title": "Installing MADS",
    "section": "",
    "text": "Suppose that you downloaded the installer mads-&lt;version&gt;-Darwin-universal.sh (where &lt;version&gt; is the version number, e.g. 1.3.3). The installer takes the following arguments:\n./mads-1.3.3-Darwin-universal.sh --help\nUsage: packages/mads-1.3.3-Darwin-universal.sh [options]\nOptions: [defaults in brackets after descriptions]\n  --help            print this message\n  --version         print cmake installer version\n  --prefix=dir      directory in which to install\n  --include-subdir  include the mads-1.3.3-Darwin-universal subdirectory\n  --exclude-subdir  exclude the mads-1.3.3-Darwin-universal subdirectory\n  --skip-license    accept license\nIf you run it with no arguments, it will install MADS in the /usr/local/ directory (need sudo) and ask for accepting the license. If you (as me) prefer to keep it in your home directory, you can run:\n./mads-1.3.3-Darwin-universal.sh --prefix=${HOME} --skip-license    \nwhich will install in ${HOME}/usr/local and automatically accept license. Then, you want to add ${HOME}/usr/local/bin to your search path: add the following line to your .zshrc or .bashrc file:\nexport PATH=${HOME}/usr/local/bin:$PATH\nFinally, restart your terminal and check that MADS is correctly installed by running:\nmads --version\n\n\nUnless we’re talking of very specific use cases, you probably want to compile your own plugins. For that, you need the Apple Developer Tools installed, together with CMake and Git."
  },
  {
    "objectID": "guides/install.html#installing-on-linux",
    "href": "guides/install.html#installing-on-linux",
    "title": "Installing MADS",
    "section": "",
    "text": "On git.new/MADS you find two deb packages:\n\nmads-&lt;version&gt;-Linux-x86_64.deb for Intel architectures\nmads-&lt;version&gt;-Linux-aarch64.deb for ARM architectures (e.g. Raspberry Pi)\n\nInstalling is as simple as:\nexport MV=1.3.3  # or the latest version\nwget https://github.com/pbosetti/MADS/releases/download/v${MV}/mads-${MV}-Linux-aarch64.deb\nsudo dpkg -i mads-${MV}-Linux-aarch64.deb\nrm mads-${MV}-Linux-aarch64.deb\n\n\n\n\n\n\nNote\n\n\n\nIf you run native Linux virtual machines on MacOS with Apple Silicon chips, as for example by using OrbStack, you need to install the aarch64 version of MADS within the VM. In other words, the same binaries work on Raspberry Pi OS (Raspbian) and on a Linux native VM running on Apple Silicon.\n\n\n\n\nUnless we’re talking of very specific use cases, you probably want to compile your own plugins. For that, you need the followings:\nsudo apt update\nsudo apt install build-essential cmake git clang\nIn addition, install any other library you plan to use in the development."
  },
  {
    "objectID": "guides/install.html#installing-on-windows",
    "href": "guides/install.html#installing-on-windows",
    "title": "Installing MADS",
    "section": "",
    "text": "The Windows installer is a standard graphical exe installer. Download it from git.new/MADS and run it.\nThe installer installs MADS in C:\\Program Files\\MADS, The installer will also add the MADS bin directory to your search path.\n\n\nUnless we’re talking of very specific use cases, you probably want to compile your own plugins. For that, you need the Visual Studio 17 (Community Edition is fine) with the C++ development tools, together with CMake and Git."
  },
  {
    "objectID": "guides/contribute.html",
    "href": "guides/contribute.html",
    "title": "How to contribute",
    "section": "",
    "text": "These guides are prepared in Quarto format, which is a markdown-based format that allows for the creation of documents and websites with rich formatting and interactivity. The website structure is hosted on GitHub, and contributions can be made through pull requests."
  },
  {
    "objectID": "guides/contribute.html#prerequisites",
    "href": "guides/contribute.html#prerequisites",
    "title": "How to contribute",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nGit and a GitHub account\nAn IDE:\n\nRStudio (recommended)\nVisual Studio Code\n\nIf you opt for VS Code, you will need to install Quarto and the Quarto extension. RStudio comes with Quarto pre-packaged."
  },
  {
    "objectID": "guides/contribute.html#forking-the-repository",
    "href": "guides/contribute.html#forking-the-repository",
    "title": "How to contribute",
    "section": "Forking the repository",
    "text": "Forking the repository\nTo contribute to the MADS guides collection, you need to fork the repository. This allows you to create your own copy of the repository where you can make changes without affecting the original project. To fork the repository, follow these steps:\n\ngo to https://github.com/MADS-Net/mads-net.github.io\nclick on the “Fork” button in the top right corner of the page\nselect your GitHub account as the destination for the fork\nwait for GitHub to create the forked repository in your account"
  },
  {
    "objectID": "guides/contribute.html#authorizing-your-computer",
    "href": "guides/contribute.html#authorizing-your-computer",
    "title": "How to contribute",
    "section": "Authorizing your computer",
    "text": "Authorizing your computer\nThe best way to authorize your computer to work on GitHub repositories is to use the gh command line utility. You can get it from https://cli.github.com. Once installed, open a terminal and type:\ngh auth login\nthen follow instructions to authenticate your GitHub account. This will allow you to push changes to your forked repository and create pull requests. It is typically done once per computer."
  },
  {
    "objectID": "guides/contribute.html#cloning-the-repository",
    "href": "guides/contribute.html#cloning-the-repository",
    "title": "How to contribute",
    "section": "Cloning the repository",
    "text": "Cloning the repository\nYou cannot edit the official repository, but you can freely edit your forked repository. To do this, you need to clone the repository to your local machine. This creates a local copy of the repository that you can work on. To clone the repository, follow these steps:\n\nopen your terminal or command prompt\nnavigate to the directory where you want to clone the repository\ntype the following:\n\ngh repo clone &lt;your-username&gt;/mads-net.github.io.git\nreplacing &lt;your-username&gt; with your GitHub username. This will create a folder named mads-net.github.io in your current directory, containing the cloned repository. Then open the mads_doc.Rproj file if you are using RStudio. If you are using VSCode, just open that folder."
  },
  {
    "objectID": "guides/contribute.html#ensure-your-repository-is-up-to-date",
    "href": "guides/contribute.html#ensure-your-repository-is-up-to-date",
    "title": "How to contribute",
    "section": "Ensure your repository is up to date",
    "text": "Ensure your repository is up to date\nOther people could contribute to the guides while you are working on your own. To ensure that your repository is up to date and to minimize the risks for conflicts, you shall pull the latest changes from the original repository. To do this, follow these steps:\n# Navigate to the cloned repository folder\ncd mads-net.github.io\n# fetch any new changes from the original repository\ngit fetch upstream\n# merge the changes into your local repository\ngit merge upstream/main"
  },
  {
    "objectID": "guides/contribute.html#create-a-new-guide",
    "href": "guides/contribute.html#create-a-new-guide",
    "title": "How to contribute",
    "section": "Create a new guide",
    "text": "Create a new guide\nTo create a new guide, you can use the guides/template.qmd file as a starting point. This file contains the basic structure and formatting for a guide. Make a copy of it with a suitable name.\nIf the guide you are working is complex and is probably going to require images and/or data files, you should put the guide in a separate folder. For example, if you are writing a guide on “Data Analysis”, you could create a folder named guides/data-analysis and put the data-analysis.qmd file inside it. Quarto will automatically add that file as a new guide in the Guides page listing. Images and supporting files can then be put in the same folder, and they will be automatically linked in the guide."
  },
  {
    "objectID": "guides/contribute.html#edit-the-guide",
    "href": "guides/contribute.html#edit-the-guide",
    "title": "How to contribute",
    "section": "Edit the guide",
    "text": "Edit the guide\nThe guide YAML preamble is the first thing to edit. Ensure that you set the title, author, and date fields correctly. You can also set the categories field to categorize your guide, and the abstract field to provide a brief description of the guide.\nNote that the preamble has a draft: true field. This means that the guide will not be published until you set it to draft: false. This is useful to work on the guide without it being visible on the website or when previewing the website locally. A guide in draft mode will not be listed in the Guides page, but it will be accessible via its URL.\n\n\n\n\n\n\nNote\n\n\n\nIf you want that the guide is also available in PDF format, uncomment the preamble section for the format key. In this way, the guide will be available in both HTML and PDF formats.\n\n\nRefer to the Quarto documentation for more information on how to format the guide using Quarto markdown."
  },
  {
    "objectID": "guides/contribute.html#preview-the-guide",
    "href": "guides/contribute.html#preview-the-guide",
    "title": "How to contribute",
    "section": "Preview the guide",
    "text": "Preview the guide\nTo preview the guide, you can use the quarto preview command. This will start a local web server and open the guide in your default web browser. To do this, follow these steps:\n# Navigate to the cloned repository folder\ncd mads-net.github.io\n# Start the local web server\nquarto preview\n\n\n\n\n\n\nAutomatic refresh\n\n\n\nThe local web server will automatically refresh the page whenever you save changes to the guide files. This allows you to see the changes in real-time without having to manually refresh the page.\nHowever, some changes (e.g. adding new files) are not always detected. In these cases, you can manually refresh the page in your browser to see the changes, and if it does not work, you can stop the server with Ctrl+C and restart it with quarto preview."
  },
  {
    "objectID": "guides/contribute.html#publish-your-contribute",
    "href": "guides/contribute.html#publish-your-contribute",
    "title": "How to contribute",
    "section": "Publish your contribute",
    "text": "Publish your contribute\nWhenever you are content with your contributed guide, you can commit your work and push it to your forked repository. before doing that, however, ensure that there are no new contribution on the uspstream repository. Since you cannot pull changes on your repository if it has pending changes, you first stash your changes, i.e. you put them temporarily aside, reverting back to a clean state (the last commit, in synchron with upstream):\ngit stash\nNow you can pull the latest changes from the original repository:\n# Fetch any new changes from the original repository\ngit fetch upstream\n# Merge the changes into your local repository\ngit merge upstream/main\nAfter this, you can reapply your changes:\ngit stash pop\nIf there were new changes from upstream, and you have changed the same files, you might have to resolve conflicts. In this case, Git will show you the files with conflicts, and you will need to manually edit them to resolve the conflicts.\nA conflict is typically marked in the file with &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD, =======, and &gt;&gt;&gt;&gt;&gt;&gt;&gt; upstream/main. You need to choose which changes to keep, or merge them together, and then remove these markers. Once you are done, you can add the resolved files to the staging area, make a new commit and publish your changes on gitHub:\ngit add .\ngit commit -m \"Resolved conflicts and updated guide\"\ngit push origin main\nNow your forked repository will be ahead of the original, upstream, repository. This means that you have changes that are not yet in the original repository. So you can now create a pull request to the original repository. This will allow the maintainers of the MADS guides collection to review your changes and merge them into the main repository. To create a pull request, follow these steps:\n\ngo to your forked repository on GitHub\nclick on the “Pull requests” tab\nclick on the “New pull request” button\nselect the branch you want to merge into the original repository (usually main)\nreview the changes and add a title and description for the pull request (be informative!!!)\nclick on the “Create pull request” button\nwait for the maintainers to review your changes and merge them into the original repository"
  },
  {
    "objectID": "guides/services.html",
    "href": "guides/services.html",
    "title": "Services",
    "section": "",
    "text": "Why services\nAgents are typically expected to run on boot: as soon as the machine or device starts, you want the agent to become immediately available. To do that, MADS offers a solution for quickly create a service for a given combination of MADS command and arguments.\n\n\n\n\n\n\nWarning\n\n\n\nAt the moment, this functionality is only available on Linux (Ubuntu or Debian). There are no immediate plans to extend it to MacOS or Windows.\n\n\n\n\nWhat is a service\nOn Ubuntu or Debian Linux, a service is a INI file located in /etc/systemd/system that details a command to be executed on boot and its requirements. Once you have the service file installed, e.g. as /etc/systemd/system/my_service.service, you can:\n\nEnable/disable the service: sudo systemctl enable|disable my_service. If the service is disabled, It does not starts automatically.\nStart the service manually: sudo systemctl start my_service\nStop the service manually: sudo systemctl stop my_service\nEnquire the service status: sudo systemctl status my_service\n\nSo, if the service is enabled, it starts automatically on boot; if it is disabled, you can still start it with the systemctl start command.\n\n\nHow to create a MADS service\nSuppose that you knwo that the following command launches properly an agent:\nmads source -i in0_01 arduino.plugin\nNow you want turn this command into a service. Just put mads service &lt;service_name in forn t of that command line, e.g.:\nmads service arduino source -i in0_01 arduino.plugin\nwhere mads service arduino means “create a service file called mads-arduino” (mads- is added automatically), and source -i in0_01 arduino.plugin is the proper command line for the mads command.\nYou should get an output like:\n#  __  __    _    ____  ____\n# |  \\/  |  / \\  |  _ \\/ ___|\n# | |\\/| | / _ \\ | | | \\___ \\\n# | |  | |/ ___ \\| |_| |___) |\n# |_|  |_/_/   \\_\\____/|____/\n#\n# Linux Systemd service file for mads-arduino, a mads-source agent\n# Notice that the settings file will be read from\n# /usr/local/etc/mads.ini\n#\n# Save this file to /etc/systemd/system/mads-arduino.service\n# Or run \"sudo mads service publish source publish.plugin \"\n# then run \"sudo systemctl enable mads-arduino.service\"\n\n[Unit]\nDescription=mads-arduino\nAfter=network.target\nStartLimitIntervalSec=0\n\n[Service]\nType=simple\nRestart=always\nRestartSec=1\nUser=root\nExecStart=/usr/local/bin/mads-source -i in0_01 arduino.plugin\n\n[Install]\nWantedBy=multi-user.target\nAs instructed in the comments, you shall check if everything looks fine, and if so, install the service file in the proper directory by simply re-executing the same command with sudo :\nsudo mads service arduino source -i in0_01 arduino.plugin\nA longer and more flexible path is to save the file locally, edit it to taste, then manually copy/move it to /etc/systemd/system:\nmads service arduino source -i in0_01 arduino.plugin &gt; mads-arduino.service\n# edit the file to taste\nsudo cp mads-arduino.service /usr/systemd/system/\n\n\n\n\n\n\nTip\n\n\n\nThe fist way is the suggested one, unless you really need to adjust the service file (and you know what you are doing).\n\n\nFinally, enable the service with sudo systemctl enable mads-arduino.service.\nNote that enabling the service does not makes it start: to do so, you either have to reboot the machine or to manually start with sudo systemctl start mads-arduino.service.\n\n\nSpecial case: broker service\nThe broker launched as mads broker interacts with the console, waiting for keystrokes. This is not ideal for a service, and would increase the CPU load unnecessarily.\nTo avoid this problem, the broker shall be called with the -d (daemon) option:\nsudo mads service broker broker -d\n\n\n\n\n Back to top"
  },
  {
    "objectID": "guides/monolithic_agents.html",
    "href": "guides/monolithic_agents.html",
    "title": "Monolithic agents",
    "section": "",
    "text": "Sometimes, the constraints posed by the MADS plugin architecture won’t fit your use case. When you are using MADS plugins, in fact, you are limited to implement a source, a filter, or a sink. But if the behavior of you agent is not that clearly defined, then you need to build your own monolithic agent.\nTypically, this is the case when the agent behavior depends upon some state parameter. Suppose that your agent must behave as a source in some circumstances, then switch to a filter in others. Then you need to implement a monolithic agent."
  },
  {
    "objectID": "guides/monolithic_agents.html#build-system",
    "href": "guides/monolithic_agents.html#build-system",
    "title": "Monolithic agents",
    "section": "Build system",
    "text": "Build system\nUnlike for MADS plugins, there is no command (yet) to create a monolithic agent temnplate, and you need to setup the build environment by your own. Use whatever you are comfortable with, although we recommend using CMake and clang compiler on Linux and MacOS, or Visual Studio 17 on Windows (Community Edition is fine)."
  },
  {
    "objectID": "guides/monolithic_agents.html#libraries",
    "href": "guides/monolithic_agents.html#libraries",
    "title": "Monolithic agents",
    "section": "Libraries",
    "text": "Libraries\nFrom the MADS point-of-view, everything you need is already installed by the MADS installer. Simply setup your build system to search for headers and libraries in the MADS prefix directory, which you can find with mads -p command.\nYou’ll need to link against the following libraries:\n\nOn Unixes: zmqpp-static zmq snappy\nOn Windows: zmqpp-static libzmq-v143-mt-s-4_3_6 snappy Ws2_32 bcrypt Secur32 Crypt32 Dnsapi IPHLPAPI"
  },
  {
    "objectID": "guides/monolithic_agents.html#example-project",
    "href": "guides/monolithic_agents.html#example-project",
    "title": "Monolithic agents",
    "section": "Example project",
    "text": "Example project\nWe suggest to use the python agent as an example project: you can git fork it and start from there.\nIn that project, you can safely get rid of:\n\nthe python folder\nthe src/python_interpreter.hpp class\neverything related to the cppy3 library (and Python in general) in the CMakeLists.txt file.\n\nFinally, rename src/main/python.cpp to your liking (e.g. agent.cpp) and move on to the next section."
  },
  {
    "objectID": "guides/monolithic_agents.html#coding",
    "href": "guides/monolithic_agents.html#coding",
    "title": "Monolithic agents",
    "section": "Coding",
    "text": "Coding\nThe file src/main/agent.cpp (or whatever name you choose th the last step above) is divided in the following sections:\n\nParse command line options: Uses the cxxopts library to define and parse the supported CLI options; customize as needed. Remember to execute the macro SETUP_OPTIONS(options, Agent);\nInitialize agent: this section is rather general, with the exception of the lines dealing with attachments (binary objects sent to the agent by the broker upon launch). If you don’t need attachments, you can remove this section altogether;\nCLI options override: the call to agent.init() actually loads the settings from the broker, fetching the mads.ini section under agent_name and storing them in the settings JSON object. So in this section you can safely override those settings with command line options, if needed, and store them back in the settings object;\nPrint info: this section is optional, but it is a good practice to print some information about the agent, such as its name, version, and settings; info are printed on stderr, indented by two spaces;\nMain loop: this is where most of the action happens, and see the next section for details;\nCleanup: free used resources, call agent.register_event to mark the exit in the database, and restart the agent if needed (i.e. if agent.restart() is true).\n\n\n\n\n\n\n\nRemote control and agents restarting\n\n\n\nThe agent initialization calls agent.enable_remote_control(). This call makes the agent listen for a special set of commands sent by the broker, such as restart and stop, and requires a regular call to agent.remote_control() in the main loop. If you don’t need this feature, you can remove the call to enable_remote_control().\nNote, though, that without that feature you won’t be able to setup the agent for a restart in the cleanup section, because agent.restart() will always return false. The agents ability to self-restart is crucial, since it allows to restart all the agents in a network and reload the INI settings automatically from the broker.\nIn fact, when the mads.ini file on the broker machine is updated, the broker automatically reloads it and makes it available to any newly started agent, but agentts that are already running will not see the changes. So, if you want to change the settings of a running agent, you need to restart it, and this is what the remote control feature allows you to do. To restart all agents you can use the TUI plugin, or mads command restart command."
  },
  {
    "objectID": "guides/monolithic_agents.html#main-loop",
    "href": "guides/monolithic_agents.html#main-loop",
    "title": "Monolithic agents",
    "section": "Main loop",
    "text": "Main loop\nThe main loop is implemented by calling the agent.loop() method. It takes two arguments:\n\na C++17 lambda function, that grabs all the local context variables and has no arguments: [&]() { ... } (mandatory);\na std::chrono::milliseconds value, that defines the loop frequency (optional, typically read from settings and possibly overridden by a CLI option).\n\n\n\n\n\n\n\nImportant\n\n\n\nTo ensure performance and determinism, it is important to declare all objects used in the lambda before entering the loop.\n\n\nWithin the lambda loop function, you have access to the following methods:\n\nagent.receive(): to receive messages from the broker; it returns a message_type enum, that can be none, json, or blob (a binary buffer);\nagent.last_message(): to get the last received message, which is a zmqpp::message object;\nagent.last_topic(): to get the topic of the last received message, which is a std::string;\nagent.remote_control(): you must call it to process any incoming remote control message;\nagent.publish(): to publish a JSON message to the broker. If not specified as second argument, it uses the default publish topic of the agent.\n\nLook at the agent.hpp header file for the complete list of methods available in the agent class."
  },
  {
    "objectID": "guides.html",
    "href": "guides.html",
    "title": "Guides",
    "section": "",
    "text": "Spotlight\n\n\n\nBe sure to start with MADS structure guide.\nIf you want to contribute, head on to the contribution guide.\n\n\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\nDescription\n\n\n\nCategories\n\n\n\nReading Time\n\n\n\n\n\n\n\n\nSep 3, 2025\n\n\nAgents persistency with Datastore\n\n\nPaolo Bosetti\n\n\nMADS Version 1.3.5 introduces the Datastore class for plugins. This class allows storing persistent information at device level. \n\n\nplugin, C++, intermediate\n\n\n5 min\n\n\n\n\n\n\nAug 30, 2025\n\n\nInteracting with MADS\n\n\nPaolo Bosetti\n\n\nThis guide illustrates the various ways to interact with MADS by publishing one-shot JSON messages to the MADS broker. \n\n\neasy, operations\n\n\n6 min\n\n\n\n\n\n\nAug 27, 2025\n\n\nInstalling MADS\n\n\nPaolo Bosetti\n\n\nA brief how to for installing MADS on different operating systems. \n\n\nconfiguration, setup, how-to, easy\n\n\n5 min\n\n\n\n\n\n\nAug 8, 2025\n\n\nMonolithic agents\n\n\nPaolo Bosetti\n\n\nHow to develop a custom monolithic agent by exploiting the MADS C++17 library. \n\n\nadvanced, development, c++\n\n\n5 min\n\n\n\n\n\n\nJul 11, 2025\n\n\nHDF5 Logger\n\n\nPaolo Bosetti\n\n\nMADS comes packaged with a logging facility to MongoDB database. For some applications, a file-based logging system is more appropriate. This guide explains how to use the HDF5 logger, which is a file-based sink for MADS using the hierarchical data format. \n\n\nplugin, sink, hdf5, logging, data\n\n\n7 min\n\n\n\n\n\n\nJul 7, 2025\n\n\nOTA Plugins\n\n\nPaolo Bosetti\n\n\nMADS Version 1.3.0 introduces the possibility to load plugins Over-The-Air (OTA): plugin files can be provided to agents by the broker. This allows to centralize the management of plugins and to update them without the need to manually copy compiled plugins to the devices running the agents. \n\n\nplugin, OTA, over-the-air, intermediate\n\n\n7 min\n\n\n\n\n\n\nJul 7, 2025\n\n\nParallel computing with MADS\n\n\nPaolo Bosetti\n\n\nMADS has two special agents, dealer and worker, that allow to distribute many different computations to a set of identical workers, in round-robin fashion. \n\n\nplugin, parallel computing, advanced, kubernetes, docker\n\n\n7 min\n\n\n\n\n\n\nJun 6, 2025\n\n\nServices\n\n\nPaolo Bosetti\n\n\nOnce tested, agents can be turned into linux services, so that they start automatically on boot. \n\n\nintermediate, OS, setup, easy\n\n\n3 min\n\n\n\n\n\n\nJun 6, 2025\n\n\nPlugins\n\n\nPaolo Bosetti\n\n\nMADS supports agents implemented as plugins in C++17. This guide explains how to create a plugin. \n\n\nadvanced, plugin, development, c++\n\n\n4 min\n\n\n\n\n\n\nJun 4, 2025\n\n\nNetwork structure\n\n\nPaolo Bosetti\n\n\nIllustrate a typical MADS network structure and its requirements. \n\n\ntemplate, basics, easy\n\n\n5 min\n\n\n\n\n\n\nJun 2, 2025\n\n\nHow to contribute\n\n\nPaolo Bosetti\n\n\nWe explain how to contribute to the MADS guides collection. \n\n\nhow-to, easy\n\n\n7 min\n\n\n\n\n\n\nJun 2, 2025\n\n\nContainerized MADS\n\n\nPaolo Bosetti\n\n\nThe base agents for setting up a MADS network are available as a containerized environment. \n\n\ndocker, easy, OS, setup\n\n\n3 min\n\n\n\n\n\n\nJun 2, 2025\n\n\nRaspberry Pi IO\n\n\nPaolo Bosetti\n\n\nThe rpio.plugin allows low-latency interaction with Raspberry Pi GPIO pins via libgpiod library. \n\n\nintermediate, RaspberryPi, IO, plugin\n\n\n5 min\n\n\n\n\n\n\nJun 2, 2025\n\n\nPython Agent\n\n\nPaolo Bosetti\n\n\nThe python_agent repo on GitHub provides a MADS agent with an embedded python3 interpreter for developing MADS sgents in Python \n\n\npython, agent, easy\n\n\n4 min\n\n\n\n\n\n\nJun 2, 2025\n\n\nZeroConf (aka Avahi) network discovery\n\n\nPaolo Bosetti\n\n\nUsing hostnames rather than IP addresses is easier and much more robust. In this guide, we learn how to setup a Linux box for advertising its address by using the Avahi protocol/service. \n\n\nnetworking, IP, configuration, OS, Linux\n\n\n2 min\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "who_is_using.html",
    "href": "who_is_using.html",
    "title": "Who is using ",
    "section": "",
    "text": "Within the national research project “Miroscic”, Paolo Bosetti has originally developed MADS as a way to orchestrate and manage the data acquired from a collection of heterogeneous sensors, including smart cameras, ToF cameras, and other IoT devices for ensuring safety of operators in industrial environments.\nThe MADS architecture is currently being used by researchers in the MiRO lab for building the software stack of a robotic walker for rehabilitation of patients with neurological disorders.\n\n\n\nWithin the national research project “Miroscic”, the group of prof. Matteo Lancini of the MMTLab of the University of Brescia is using MADS to develop the edge cameras and software that provides 3D estimate of human pose by using AI techniques.\n\n\n\nWithin the national research project “Miroscic”, the group of prof. Roberto Marsili at the Measurement Group of the University of Perugia is using MADS collect data from wearable sensors and RFID transponders.\n\n\n\nThe group coordinated by prof. Anna-Carla Araujo at the INSA Toulouse, SUMO group of Institut Clément Ader is using MADS to collect data from multiple sensors in a machining shopfloor, with the aim of measuring and improving energy efficiency of the production processes."
  },
  {
    "objectID": "who_is_using.html#university-of-trento-italy",
    "href": "who_is_using.html#university-of-trento-italy",
    "title": "Who is using ",
    "section": "",
    "text": "Within the national research project “Miroscic”, Paolo Bosetti has originally developed MADS as a way to orchestrate and manage the data acquired from a collection of heterogeneous sensors, including smart cameras, ToF cameras, and other IoT devices for ensuring safety of operators in industrial environments.\nThe MADS architecture is currently being used by researchers in the MiRO lab for building the software stack of a robotic walker for rehabilitation of patients with neurological disorders."
  },
  {
    "objectID": "who_is_using.html#university-of-brescia-italy",
    "href": "who_is_using.html#university-of-brescia-italy",
    "title": "Who is using ",
    "section": "",
    "text": "Within the national research project “Miroscic”, the group of prof. Matteo Lancini of the MMTLab of the University of Brescia is using MADS to develop the edge cameras and software that provides 3D estimate of human pose by using AI techniques."
  },
  {
    "objectID": "who_is_using.html#university-or-perugia-italy",
    "href": "who_is_using.html#university-or-perugia-italy",
    "title": "Who is using ",
    "section": "",
    "text": "Within the national research project “Miroscic”, the group of prof. Roberto Marsili at the Measurement Group of the University of Perugia is using MADS collect data from wearable sensors and RFID transponders."
  },
  {
    "objectID": "who_is_using.html#insa-toulouse-france",
    "href": "who_is_using.html#insa-toulouse-france",
    "title": "Who is using ",
    "section": "",
    "text": "The group coordinated by prof. Anna-Carla Araujo at the INSA Toulouse, SUMO group of Institut Clément Ader is using MADS to collect data from multiple sensors in a machining shopfloor, with the aim of measuring and improving energy efficiency of the production processes."
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "Why ?",
    "section": "",
    "text": "Sure there are! ROS2 is a very popular framework for robotics, and it has a lot of features that MADS does not have. However, ROS2 is not as lightweight as MADS. If you need a full-fledged robotics framework, ROS2 is a great choice. If you need a lightweight framework, MADS has some advantages over ROS2. Of course, advantages come to a cost, and MADS is not as feature-rich (nor it is as mature) as ROS2.\nWe’ll see here the main differences between MADS and ROS2.\n\n\n\n\nMADS installers weight about 8 Mb (twice as much for MacOS dual architecture installer), and they have minimal dependencies on most platforms. By comparison, ROS2 installers are about 750 Mb. Installing and configuring a ROS2 workspace is a complex task, while MADS can be installed in a few seconds and it is ready to use.\nIf you know what you are doing, you can be up and running in a simple data collection MADS network in about one hour.\nWhat really makes the difference, though, is the learning curve:\n\n\n\n\n\n\n\n\n\nWhile ROS/ROS2 is a complex framework that requires a lot of time to grasp and master, MADS is a simple framework that can be learned in a few hours. The learning curve is much more gentle, and you can start using MADS for your projects in a very short time.\nAt the same time, ROS2 is much more mature and feature rich: there is a lot of pre-existing code, libraries, and tools that you can use to build your robotics applications. MADS is not as mature, and it does not have as many features, but it is lightweight and easy to use.\nThe plugin architecture of MADS allow to extend the framework with minimum knowledge and an API that virtually consists in no more than 5 methods. If performance is not critical, MADS agents can be written in Python.\n\n\n\nROS and ROS2 are typically not as easy to install and configure, and their reference platform is Ubuntu Linux. It is much more difficult to run ROS2 on Windows (without virtualization), almost impossible on MacOS, and it’s difficult on small systems as Raspberry Pi. MADS, on the other hand, is designed to be lightweight and easy to install on any platform, including Windows, MacOS, Linux, and small systems like Raspberry Pi.\nOn any system that is not supported by official installer, and that has a C++17 compiler (preferably clang), CMake, and git, MADS can be compiled in minutes / tens of minutes from source.\n\n\n\nBeing the MADS codebase smaller and simpler, it is also easier to adapt it and extend it to your needs. If you need a specific feature that is not available in MADS, you can easily implement it by yourself. The MADS community is small but growing, and we are always happy to help.\n\n\n\nMADS uses ZeroMQ as its communication layer, which is a lightweight and efficient messaging library. ZeroMQ is designed to be fast and scalable, and it is used by many other projects.\nWith respect to networking middleware used by ROS2 (DDS), ZeroMQ id much more flexible and can be adapted to different use cases and network topologies.\n\n\n\n\n\n\nIf you need hard real-time, MADS is probably not yet ready and will suffer of the lack of determinism of a TCP-based communication layer. But if a jitter in the range of milliseconds is acceptable, MADS can be used in real-time applications, preferably using PREEMPT-RT Linux kernels.\n\n\n\nMADS uses compressed JSON for data serialization. This choice has the advantage of being human-readable, easy to debug, and really flexible when it comes to adapting the data scheme to different choices taken during the development. On the other hand, serialization/deserialization is not extremely efficient and the used bandwidth is sub-optimal.\nOn the other hand, MADS supports binary attachments to any message: so if JSON-based communication performance is not enough, you can use a minimum JSON data packet with a binary attachment that encodes data in a more efficient way (e.g. by using protobufs or Cap’n’Proto)."
  },
  {
    "objectID": "why.html#advantages-over-ros2",
    "href": "why.html#advantages-over-ros2",
    "title": "Why ?",
    "section": "",
    "text": "MADS installers weight about 8 Mb (twice as much for MacOS dual architecture installer), and they have minimal dependencies on most platforms. By comparison, ROS2 installers are about 750 Mb. Installing and configuring a ROS2 workspace is a complex task, while MADS can be installed in a few seconds and it is ready to use.\nIf you know what you are doing, you can be up and running in a simple data collection MADS network in about one hour.\nWhat really makes the difference, though, is the learning curve:\n\n\n\n\n\n\n\n\n\nWhile ROS/ROS2 is a complex framework that requires a lot of time to grasp and master, MADS is a simple framework that can be learned in a few hours. The learning curve is much more gentle, and you can start using MADS for your projects in a very short time.\nAt the same time, ROS2 is much more mature and feature rich: there is a lot of pre-existing code, libraries, and tools that you can use to build your robotics applications. MADS is not as mature, and it does not have as many features, but it is lightweight and easy to use.\nThe plugin architecture of MADS allow to extend the framework with minimum knowledge and an API that virtually consists in no more than 5 methods. If performance is not critical, MADS agents can be written in Python.\n\n\n\nROS and ROS2 are typically not as easy to install and configure, and their reference platform is Ubuntu Linux. It is much more difficult to run ROS2 on Windows (without virtualization), almost impossible on MacOS, and it’s difficult on small systems as Raspberry Pi. MADS, on the other hand, is designed to be lightweight and easy to install on any platform, including Windows, MacOS, Linux, and small systems like Raspberry Pi.\nOn any system that is not supported by official installer, and that has a C++17 compiler (preferably clang), CMake, and git, MADS can be compiled in minutes / tens of minutes from source.\n\n\n\nBeing the MADS codebase smaller and simpler, it is also easier to adapt it and extend it to your needs. If you need a specific feature that is not available in MADS, you can easily implement it by yourself. The MADS community is small but growing, and we are always happy to help.\n\n\n\nMADS uses ZeroMQ as its communication layer, which is a lightweight and efficient messaging library. ZeroMQ is designed to be fast and scalable, and it is used by many other projects.\nWith respect to networking middleware used by ROS2 (DDS), ZeroMQ id much more flexible and can be adapted to different use cases and network topologies."
  },
  {
    "objectID": "why.html#disadvantages-over-ros2",
    "href": "why.html#disadvantages-over-ros2",
    "title": "Why ?",
    "section": "",
    "text": "If you need hard real-time, MADS is probably not yet ready and will suffer of the lack of determinism of a TCP-based communication layer. But if a jitter in the range of milliseconds is acceptable, MADS can be used in real-time applications, preferably using PREEMPT-RT Linux kernels.\n\n\n\nMADS uses compressed JSON for data serialization. This choice has the advantage of being human-readable, easy to debug, and really flexible when it comes to adapting the data scheme to different choices taken during the development. On the other hand, serialization/deserialization is not extremely efficient and the used bandwidth is sub-optimal.\nOn the other hand, MADS supports binary attachments to any message: so if JSON-based communication performance is not enough, you can use a minimum JSON data packet with a binary attachment that encodes data in a more efficient way (e.g. by using protobufs or Cap’n’Proto)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": ": Multi-Agent Distributed System",
    "section": "",
    "text": "Important\n\n\n\n Always get the latest MADS installer on: git.new/MADS\nSee this guide for installation instructions.\n\n\n\nWhat is it\nMADS-NET is a simple framework for implementing a network of distributed agents that can exchange information via ZeroMQ.\nIt is made by a main set of executables available in the MADS tools collection repo, which also provides installers for Linux, MacOS and Windows.\nThe MADS tools collection includes a broker and a set of general purpose agents that can act as sources, filters, or sinks. The actual operations performed by agents can be customized either via scripting languages (using simple popen interface), or by implementing dedicated plugins in C++.\nSome of the available plugins are:\n\narduino_plugin: reads from a serial connected arduino\nhpe2D_plugin: performs human pose estimation from a camera stream\nmqtt_plugin: acts as a bridge with an MQTT network via two agents: mqtt2mads.plugin (source) and mads2mqtt.plugin (sink)\nsay_plugin: Text-to-speech of incoming messages\nble_plugin: Bluetooth Low Energy source plugin\ntui_plugin: Terminal User Interface for sending metadata commands to MADS network\nlua_plugin: Interfacing Lua scripts to the MADS network (useful for prototyping and rapid development)\nhdf5_plugin: a sink agent that logs data traffic into a HDF5 file\nrpio_plugin: source and sink agents for Raspberry Pi GPIO pins (using libgpiod v1.6)\n\nThere are also additional monolithic agents:\n\npython_agent: Interfacing Python3 scripts to the MADS network (useful for prototyping and rapid development)\n\nLook into the guides section for more information on how to use the MADS tools collection.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Authors",
    "section": "",
    "text": "Authors\n\nMain author\n\nPaolo Bosetti, University or Trento\n\nContributors\n\nAnna-Carla Araujo, INSA Toulouse\nGuillaume Cohen, INSA Toulouse\n\nBeta-testers\n\nMatteo Lancini, University of Brescia\nMarco Ghidelli, University of Brescia\nNicola Abeni, University of Bresicia\nFederico Paolucci, University of Perugia\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "presentations/intro.html#contents",
    "href": "presentations/intro.html#contents",
    "title": " Intro",
    "section": " Contents",
    "text": "Contents\n\nTerminology\nBasic Usage\nLinux services\nPlugins\nParallel computing"
  },
  {
    "objectID": "presentations/intro.html#lets-get-understood",
    "href": "presentations/intro.html#lets-get-understood",
    "title": " Intro",
    "section": " Let’s get understood…",
    "text": "Let’s get understood…\n\nAgent: an entity that can perceive its environment and act upon it.\nNetwork: a set of agents, possibly distributed over different devices or machines, and exchanging information via ZeroMQ/TCP connections\n\nMADS aims at being as transparent as possible w.r.t. the underlying network.\nThe same MADS network could run\n\non a single machine (via loopback connections)\nas well as on multiple machines (via TCP connections), one agent per machine\n\nAnd everything in between…"
  },
  {
    "objectID": "presentations/intro.html#mads-network-topology",
    "href": "presentations/intro.html#mads-network-topology",
    "title": " Intro",
    "section": " MADS Network Topology",
    "text": "MADS Network Topology\n\n\nTo maximize flexibility and scalability, MADS networks are broker-based\n\nonly IP/hostname of broker is needed\nbroker does message dispatching\nagents can filter messages by topics\nagents can be added/removed dynamically\nagents can act as source, filter, or sink\n\n\n\n\n\n\n\n\n\nG\n\n\n\nbroker\n\nBroker\n\n\n\na4\n\nAgent 4\n\n\n\nbroker-&gt;a4\n\n\n\n\n\na5\n\nAgent 5\n\n\n\nbroker-&gt;a5\n\n\n\n\n\na6\n\nAgent 6\n\n\n\nbroker-&gt;a6\n\n\n\n\n\na7\n\nAgent 7\n\n\n\nbroker-&gt;a7\n\n\n\n\n\na1\n\nAgent 1\n\n\n\na1-&gt;broker\n\n\n\n\n\na2\n\nAgent 2\n\n\n\na2-&gt;broker\n\n\n\n\n\na3\n\nAgent 3\n\n\n\na3-&gt;broker\n\n\n\n\n\na4-&gt;broker\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlso see the guide page on MADS network topology"
  },
  {
    "objectID": "presentations/intro.html#its-a-zeromq-network",
    "href": "presentations/intro.html#its-a-zeromq-network",
    "title": " Intro",
    "section": " It’s a ZeroMQ network",
    "text": "It’s a ZeroMQ network\nMADS uses ZeroMQ as the underlying communication layer:\n\nconnections are established via TCP (XPUB-XSUB)\norder of connection does not matter\ndisconnection/reconnection is handled automatically\nminimum overhead w.r.t. other protocols (e.g., HTTP, gRPC, REST)\napplication-layer protocol is agnostic to the underlying transport, and left to the user\nMADS is designed to be simple, so data on the wire is presented as JSON compressed with snappy\nMADS is designed to be scalable: you can have hundreds of agents, the limiting factor being network bandwidth"
  },
  {
    "objectID": "presentations/intro.html#agents",
    "href": "presentations/intro.html#agents",
    "title": " Intro",
    "section": " Agents",
    "text": "Agents\n\n\nAgents are the building blocks of a MADS network. They can be:\n\nSources: produce data and send it to the network\nFilters: process data received from the network and send it to other agents\nSinks: consume data from the network and perform actions based on it\n\nAgents can be implemented in any programming language that supports ZeroMQ, but MADS provides C++ API that abstracts ZeroMQ intricacies.\n\n\n\n\nAgent Smith"
  },
  {
    "objectID": "presentations/intro.html#agents-1",
    "href": "presentations/intro.html#agents-1",
    "title": " Intro",
    "section": " Agents",
    "text": "Agents\n\n\nUsing MADS API, agents can be implemented as:\n\nmonolithic: a single executable that contains all the logic\nplugin-based: a general purpose executable that loads plugins dynamically, allowing for modularity and extensibility; the user only has to develop the plugin with minimal boilerplate code and API knowledge\nPython modules: MADS agent can load at runtime Python modules that provide a proper interface (2-3 functions)\n\n\n\n\n\n\nAgent Smith\n\n\n\n\nPlugins are actually shared C++ libraries, compiled with minimal dependencies"
  },
  {
    "objectID": "presentations/intro.html#implementation",
    "href": "presentations/intro.html#implementation",
    "title": " Intro",
    "section": " Implementation",
    "text": "Implementation\n\nMADS is implemented in C++17 and provides an API to create agents and connect them to the network\nIt can be compiled on Linux, macOS, and Windows\nCompilation is rather tedious and has a number of dependencies, but:\n\ninstallers are available for Linux, MacOS, and Windows\na Docker image is available for easy setup\n\nDeveloping custom agents as plugins is much easier, as it requires only a few functions to be implemented\nExample plugins are available on GitHub\nThe main MADS command can generate a plugin template"
  },
  {
    "objectID": "presentations/intro.html#main-command-mads",
    "href": "presentations/intro.html#main-command-mads",
    "title": " Intro",
    "section": " Main command: mads",
    "text": "Main command: mads\n\nThe standard installers provide a main command: mads\nInline help is available with mads --help:\n&gt; mads --help\nMads command line interface version 1.3.1\nUsage:\n  mads [OPTION...]\n\n  -i, --info     Print information on MADS installation\n  -p, --prefix   Print MADS install prefix\n      --plugins  List plugins in default plugins directory\n  -v, --version  Print version\n  -h, --help     Print help\nOptions -i and -p are useful to check the installation"
  },
  {
    "objectID": "presentations/intro.html#mads-subcommands",
    "href": "presentations/intro.html#mads-subcommands",
    "title": " Intro",
    "section": " Mads subcommands",
    "text": "Mads subcommands\n\nThe list of available mads sub commands can be obtained as:\n\n\n\n&gt; mads\nAvailable mads subcommands:\n   filter (wraps mads-filter)\n   worker (wraps mads-worker)\n  command (wraps mads-command)\n    image (wraps mads-image)\n feedback (wraps mads-feedback)\n  logging (wraps mads-logging)\n   plugin (wraps mads-plugin)\n   source (wraps mads-source)\n   bridge (wraps mads-bridge)\n     sink (wraps mads-sink)\n   dealer (wraps mads-dealer)\n   python (wraps mads-python)\n   logger (wraps mads-logger)\n   broker (wraps mads-broker)\n      ini (internal)\n  service (internal)\n\n\nOn MacOS and Linux, commands are available as e.g. mads source or mads-source\nOn Windows, commands are available as e.g. mads-source only\ninternal commands are implemented by the mads executable\nMan pages are available (e.g. man mads-source)"
  },
  {
    "objectID": "presentations/intro.html#launching-the-broker",
    "href": "presentations/intro.html#launching-the-broker",
    "title": " Intro",
    "section": " Launching the broker",
    "text": "Launching the broker\n&gt; mads broker\nReading settings from /Users/p4010/usr/local/etc/mads.ini [broker]\nBinding broker frontend (XSUB) at tcp://*:9090\nBinding broker backend (XPUB) at tcp://*:9091\nBinding broker shared settings (REP) at tcp://*:9092\nTimecode FPS: 25\nSettings are provided via tcp://127.0.0.1:9092\nCTRL-C to immediate exit\nType P to pause, R to resume, I for information, Q to clean quit, X to restart and reload settings\n\nLine 2 and 7 report a fundamental aspect: the centralized settings file\nSettings for all agents are stored in a TOML file, which is dispatched by the broker to the agents upon launch\nEach agent is launched with the settings URL (e.g. tcp://127.0.0.1:9092) as a command line argument"
  },
  {
    "objectID": "presentations/intro.html#running-an-agent",
    "href": "presentations/intro.html#running-an-agent",
    "title": " Intro",
    "section": " Running an agent",
    "text": "Running an agent\n\n\n\nTo run an agent on a device different from the one running the broker, we need to specify the broker address\nWe see relevant agent settings (loaded from broker):\n\npub topic: messages are tagged with publish\ncompression: JSON compressed with snappy\ntimecode: all messages generated in the same 40ms share the same timecode\ntimecode offset: clock difference with broker\n\n\n\n\n\n\n\nClick on the white triangle  to start the clip 😉"
  },
  {
    "objectID": "presentations/intro.html#logging-data",
    "href": "presentations/intro.html#logging-data",
    "title": " Intro",
    "section": " Logging data",
    "text": "Logging data\n\nData flowing on the MADS network can be logged for later analysis\nMADS provides two official logging facilities:\n\na MongoDB logger\nan HDF5 logger\n\nRegardless the logging facility, each message is stored as a JSON document with some added common fields:\n\ntimecode: the time when the data was produced as a multiple of a fixed timestep (e.g. 40ms). Measured in seconds from last midnight (local time)\ntimestamp: an ISO 8601 timestamp of the data\nhostname: the hostname of the machine that produced the data"
  },
  {
    "objectID": "presentations/intro.html#logger",
    "href": "presentations/intro.html#logger",
    "title": " Intro",
    "section": " Logger",
    "text": "Logger\n\nMADS provides an agent called logger for logging messages\nThe logger is designed to store data into a MongoDB database\nMongoDB is schemaless, so it can store any JSON data published to the MADS network\nEach agent publishes on a given topic (e.g. publish)\nFor each topic, a corresponding table is created in the database, and each message is stored as a document in that table\nEach document has additional fields: timecode (a fixed timestep in ms), timestamp (and ISO 8601 time), and hostname\nMongoDB aggregations can offload some computational load and make data easier to fetch\n\n\n\n\n\n\n\nNote\n\n\nA MongoDB instance can be easily started with Docker:\n&gt; docker run -d --name mads-mongo -p 27017:27017 -v ${PWD}/db:/data/db mongo"
  },
  {
    "objectID": "presentations/intro.html#hdf5-logger",
    "href": "presentations/intro.html#hdf5-logger",
    "title": " Intro",
    "section": " HDF5 logger",
    "text": "HDF5 logger\n\nAmong the official MADS plugins, there is also an HDF5 logger\nThe hdf5_writer.plugin is a MADS sink that stores data in an HDF5 file\nWithin the HDF5 file, each topic goes into a separate group\nmessages are queued, so a scalar becomes a vector, a vector becomes a table\nthe INI file must specify which data has to be saved, using a keypath syntax: \"key1.subkey2.subsubkey3\" corresponds to JSON fields data[\"key1\"][\"subkey2\"][\"subsubkey3\"]\ntimestamp, timecode, and hostname are automatically recorded into separate datasets\n\n\n\n\n\n\n\nNote\n\n\nThe plugin is available on https://github.com/MADS-Net/hdf5_plugin\n\n\n\n\n\nAlso see the guide page for more details on the hdf5_writer.plugin"
  },
  {
    "objectID": "presentations/intro.html#mads-services",
    "href": "presentations/intro.html#mads-services",
    "title": " Intro",
    "section": " MADS services",
    "text": "MADS services\nOn Linux machine only, MADS provides a service file generator that can be used to run MADS agents as system services, automatically active on boot\nProcedure:\n\ndefine the proper launch command, e.g. mads source -s tcp://mads-broker.local:9092 -n my_datasource\nrun mads service my_datasource source -s tcp://mads-broker.local:9092 -n my_datasource; this prints a possible systemctl file for a service called my_datasource.service\nif it looks correct, run the same command as sudo: this installs the service on the system dir\nenable the service: sudo systemctl enable my_datasource.service\n\n\n\nAlso see the guide page"
  },
  {
    "objectID": "presentations/intro.html#motivation",
    "href": "presentations/intro.html#motivation",
    "title": " Intro",
    "section": " Motivation",
    "text": "Motivation\n\nMADS is designed to be simple, but it can be complex to implement agents\nImplementing an agent (monolithic) requires knowledge of the MADS API, ZeroMQ\nCompiling the agent takes time and requires a proper development environment, especially on Windows\nWe wanted to let users focus on the agent logic, not on the boilerplate code\nAt the same time, we wanted to keep the advantages of C++ (performance, low-level control, etc.), without forcing users to revert to scripting interfaces just because the whole C++ framework is too complex\n\nSolution: MADS plugins"
  },
  {
    "objectID": "presentations/intro.html#mads-plugins",
    "href": "presentations/intro.html#mads-plugins",
    "title": " Intro",
    "section": " MADS plugins",
    "text": "MADS plugins\n\nA plugin is a shared library that implements a specific agent logic\nPlugins are loaded dynamically by the MADS general purpose executables:\n\nmads source: provides information to the network (e.g. by reading sensors)\nmads filter: processes data received from the network and sends it to other agents\nmads sink: consumes data from the network and performs actions based on it (e.g. by writing to a file)\n\nThe specific agent logic is implemented in the plugin, which is a C++ class that inherits from a base class\nMADS provides the mads plugin command to create a plugin template\n\n\n\nAlso see the guide page for more details on plugins"
  },
  {
    "objectID": "presentations/intro.html#running-mads-plugin",
    "href": "presentations/intro.html#running-mads-plugin",
    "title": " Intro",
    "section": " Running mads plugin",
    "text": "Running mads plugin\n\n\n\nThe mads plugin command creates a plugin template in the current directory\nThe template contains a CMakeLists.txt file and a src directory with the plugin source code\nThe template has minimal dependencies:\n\nA C++17 compliant compiler (VS 2017 or later, GCC 7 or later, Clang 5 or later)\nCMake 3.15 or later\nAny other dependency must be added to CMakeLists.txt\n\nCMake can be configured to install the plugin in the MADS plugins directory, so that the plugin is automatically found"
  },
  {
    "objectID": "presentations/intro.html#plugin-class-details",
    "href": "presentations/intro.html#plugin-class-details",
    "title": " Intro",
    "section": " Plugin class details",
    "text": "Plugin class details\nclass My_sourcePlugin : public Source&lt;json&gt; {\npublic:\n  // Implement the actual functionality here\n  return_type get_output(json &out,\n                         std::vector&lt;unsigned char&gt; *blob = nullptr) override {\n    // Your logic to fill 'out' with data\n    // optionally use 'blob' for binary content\n  }\n\n  // Run only once upon start\n  void set_params(void const *params) override {\n    // Optional: handle parameters passed to the plugin\n    // This can be used to configure the plugin at runtime\n  }\nprivate:\n  // custom fields here\n};\n// Macro that does the magic of allowing dlopen to work\nINSTALL_SOURCE_DRIVER(My_sourcePlugin, json)"
  },
  {
    "objectID": "presentations/intro.html#plugin-class-details-1",
    "href": "presentations/intro.html#plugin-class-details-1",
    "title": " Intro",
    "section": " Plugin class details",
    "text": "Plugin class details\n\nImplementing a plugin does not require knowledge of the MADS API\nOnly two methods (three methods for filter plugins) need to be implemented\nAny third party library is left to the user:\n\nadd necessary find_package calls in CMakeLists.txt\nlink the library to the plugin\ninclude the necessary headers in the plugin source code\n\nThe plugin source code also has a template main() function: beside each plugin, a one-shot executable is provided (and compiled) that can be used to test the plugin logic without the need of a MADS network\n\n\n\nNote: the CMakeLists.txt provides an add_plugin(name SRCS &lt;source lists&gt; LIBS &lt;libraries list&gt;) macro that simplifies the process of creating a plugin target"
  },
  {
    "objectID": "presentations/intro.html#ota-plugins",
    "href": "presentations/intro.html#ota-plugins",
    "title": " Intro",
    "section": " OTA plugins",
    "text": "OTA plugins\n\nPlugins can be loaded Over-The-Air (OTA) by the mads source, mads filter, and mads sink commands\nIf the INI file contains an entry like this:\n[my_source]\nattachment = \"/path/to/my_source.plugin\"\nthen that file (on the broker filesystem!) is sent to my_source agents when they connect to the broker\nThis allows to have all plugins in a single location, and to update them without having to manually copy them to each agent machine"
  },
  {
    "objectID": "presentations/intro.html#the-dealer-worker-model",
    "href": "presentations/intro.html#the-dealer-worker-model",
    "title": " Intro",
    "section": " The dealer-worker model",
    "text": "The dealer-worker model\nSuppose that you want to explore a large domain of parameters for a simulation to perform sensitivity analysis or parameters optimization:\n\n\n\nZeroMQ provides a special PUSH-PULL communication model between a single dealer and multiple, identical workers\nThe dealer distributes tasks to the workers in a round-robin fashion\nEach worker processes the task and sends the result back to the broker\nIn a possible implementation, a source provides the grid of parameters combination and a logger agent store the results\n\n\n\n\n\n\n\n\n\nDealer-worker\n\n\n\nbroker\n\nbroker\n\n\n\ndealer\n\ndealer\n\n\n\nbroker-&gt;dealer\n\n\n\n\n\nlogger\n\nlogger\n\n\n\nbroker-&gt;logger\n\n\n\n\n\nsource\n\nsource\n\n\n\nsource-&gt;broker\n\n\n\n\n\nw1\n\nworker 1\n\n\n\ndealer-&gt;w1\n\n\n\n\n\nw2\n\nworker 2\n\n\n\ndealer-&gt;w2\n\n\n\n\n\nw3\n\nworker 3\n\n\n\ndealer-&gt;w3\n\n\n\n\n\nw4\n\nworker 4\n\n\n\ndealer-&gt;w4\n\n\n\n\n\nmongo\n\n\nMongoDB\n\n\n\nw1-&gt;broker\n\n\n\n\n\np\n\nPlugin\n\n\n\nw1-&gt;p\n\n\n\n\nw2-&gt;broker\n\n\n\n\n\nw2-&gt;p\n\n\n\n\nw3-&gt;broker\n\n\n\n\n\nw3-&gt;p\n\n\n\n\nw4-&gt;broker\n\n\n\n\n\nw4-&gt;p\n\n\n\n\nlogger-&gt;mongo\n\n\nBSON\n\n\n\n\n\n\n\n\n\n\n\nAlso see the guide page"
  },
  {
    "objectID": "presentations/intro.html#the-mads-implementation",
    "href": "presentations/intro.html#the-mads-implementation",
    "title": " Intro",
    "section": " The MADS implementation",
    "text": "The MADS implementation\nIn MADS, there are two special agents for this purpose: dealer and worker\n\ndealer: receives the computational payloads (simulation input) from a suitable source agent, and dispatches them to the workers\nworker: receives the computational payloads and uses a custom plugin to process them (of type filter), then sends the results back to the broker\n\nIdeally, the worker plugin is launched in \\(n\\) instances on a Kubernetes cluster; each instance loads the computational plugin OTA from the broker"
  },
  {
    "objectID": "guides/datastore.html",
    "href": "guides/datastore.html",
    "title": "Agents persistency with Datastore",
    "section": "",
    "text": "MADS agents load their setting from the centralized mads.ini file provided by the broker. Those settings are of course read-only, i.e., it is not possible for an agent to update its settings.\nThis limitation is by design. In fact, allowing a single agent to update the setting file would possibly result in unwanted side effect: what happens if the update contains errors? what happens if there are multiple agents sharing the same name (and thus the same INI section) but having different agent_id? Forcing read-only settings is a way for ensuring robustness in operations.\nNevertheless, there are cases where an agent needs to permanently and locally store own information that has to be persistent upon the agent’s restarts. For example, suppose that you have an agent providing IMU (inertial unit) measurements with respect to an initial reference orientation. In this case, you want the agent to calibrate it’s initial attitude upon the very first launch, and then use the same calibration even when the agent restarts or the device reboots, until explicitly forced to re-calibrate. To build on the previously cited use case, the same agent running on different devices, you want to store the calibration locally, to ensure that each instance of the same agent always loads its own calibration.\nIn this scenario, you need persistent data storage, and that is what the Datastore C++ class provides."
  },
  {
    "objectID": "guides/datastore.html#the-datastore-class",
    "href": "guides/datastore.html#the-datastore-class",
    "title": "Agents persistency with Datastore",
    "section": "The Datastore class",
    "text": "The Datastore class\nIt is a C++ header-only class, provided by the plugin base project and classes. This project is automatically fetched for you whenever you compile a new plugin, and provides the base code, on top of which plugins are built. In particular, it provides the base classes Source, Filter, and Sink, that are inherited by actual plugin classes.\nThe source code of this project is downloaded into build/_deps/plugin-src in each plugin project directory.\nStarting from version 1.3.5, the code in build/_deps/plugin-src/src also provides a datastore.hpp class implementation. It is a relatively simple class for persistently store a nlohmann::json object on a text file in a local temporary folder (your OS temp dir as provided by C++ std::filesystem::temp_directory_path()). The class has the following notable methods:\n\nvoid prepare(std::string name): to be called once, it prepares a datastore file: if it exists, the file is read and parsed as a nlohmann::json object internally stored; if it does not exist, it is created (in the OS temp dir) and the internal storage set to an empty nlohmann::json object. If the name lacks the .json extension, that is automatically added.\nvoid save(): force dumping the current internal storage in the associated file. It is automatically called when the datastore is destructed (for example upon regular exit).\nnlohmann::json & operator[](const std::string &key): access the object at key from the internal storage (both for reading and writing).\nnlohmann::json & data(): provides access to the internal storage.\nstd::string path(): provides the full path of the storage file"
  },
  {
    "objectID": "guides/datastore.html#the-plugin-template",
    "href": "guides/datastore.html#the-plugin-template",
    "title": "Agents persistency with Datastore",
    "section": "The plugin template",
    "text": "The plugin template\nThe command mads plugin is used to generate a plugin template. With v1.3.5, it gains the -s|--datastore option, which enables some example calls to the Datastore class. For example, by issuing:\nmads plugin -d test_plugin -s test\nthe template for a blank new plugin called test.plugin is created in the test_plugin directory, with usage examples for Datastore. With the -sflag, the src/test.cpp file has the following additions:\n\nThe Datastore class is included with #include &lt;datastore.hpp&gt;\nThe private instance member variable Datastore _datastore is added to the TestPlugin class\nin set_params(), the line _datastore.prepare(kind()); prepares the datastore to a file named as the plugin (kind() method) with the .json extension. If that file exists, it loads its content\nsome comment lines suggest how to use the _datastore object\nthe info() method returns the full path of the storage file.\n\nSo, recalling the calibration use case referred above, the set_params() method would:\n\nprepare the datastore;\ncheck if the datastore contains the calibration: if (_datastore[\"calibration\"].empty())\n\n\nif there’s no calibration, perform the necessary calibration ops, then save the result as _datastore[\"calibration\"] = _calib_json;\nif the calibration is present, load it as _calib_json = _datastore[\"calibration\"];\n\n\nwhen the agent regularly exits, the _datastore object is destroyed and its save() method is automatically invoked, ensuring persistency\n\n\n\n\n\n\n\nTip\n\n\n\nAlthough there’s no need to explicitly save the datastore, forcing a save right after completing the calibration ensures that the calibration is saved even if there’s later a crash.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe JSON file location is in the temporary directory, which is OS dependent. Within that directory, plugin datastoires are saved in the mads subdirectory with the provided name (by default, the string returned by kind()).\nIf the map returned by info() contains a pair as {\"Datastore\", _datastore.path()}, then the datastore full path is printed in the settings table when loading the plugin with mads source|filter|sink.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf the JSON file loaded by the datastore is wrongly formatted, the prepare() method will fail throwing an exception. Catch that exception within set_params() if you can recover form the error (e.g. by performing a new calibration); or let the agent crash otherwise."
  },
  {
    "objectID": "guides/datastore.html#existing-plugins",
    "href": "guides/datastore.html#existing-plugins",
    "title": "Agents persistency with Datastore",
    "section": "Existing plugins",
    "text": "Existing plugins\nTo use the  Datastore class to an existing plugin you have to update the fetched dependency. Open the plugin’s CMakeLists.txt and change the following (note the only change at line 3):\nFetchContent_Populate(plugin \n  GIT_REPOSITORY https://github.com/pbosetti/mads_plugin.git\n  GIT_TAG        HEAD\n  GIT_SHALLOW    TRUE\n  SUBBUILD_DIR ${CMAKE_CURRENT_BINARY_DIR}/_deps/plugin-subbuild\n  SOURCE_DIR ${CMAKE_CURRENT_BINARY_DIR}/_deps/plugin-src\n  BINARY_DIR ${CMAKE_CURRENT_BINARY_DIR}/_deps/plugin-build\n)\nto:\nFetchContent_Populate(plugin \n  GIT_REPOSITORY https://github.com/pbosetti/mads_plugin.git\n  GIT_TAG        v1.3.5\n  GIT_SHALLOW    TRUE\n  SUBBUILD_DIR ${CMAKE_CURRENT_BINARY_DIR}/_deps/plugin-subbuild\n  SOURCE_DIR ${CMAKE_CURRENT_BINARY_DIR}/_deps/plugin-src\n  BINARY_DIR ${CMAKE_CURRENT_BINARY_DIR}/_deps/plugin-build\n)\nThis will force git fetching of the v1.3.5 of the plugin system.\nThen, just use the  Datastore class as above outlined (it’s source is already available in the headers search path)."
  },
  {
    "objectID": "guides/plugins.html",
    "href": "guides/plugins.html",
    "title": "Plugins",
    "section": "",
    "text": "Originally, MADS only allowed to develop monolitic agents: this required to write the whole executable code, including the management of command line arguments and loading of serrings from the INI file (either local or loaded from the broker). This solution is still possible (see the guide) and allows maximum flexibility, but it requires a good knowledse of the MADS innards and is more tedious and error prone.\nFor this reason, we developed the plugin support: the common functionality of an agent are already available, and only the data management operations need to be implemented."
  },
  {
    "objectID": "guides/plugins.html#how-to-install-the-plugin",
    "href": "guides/plugins.html#how-to-install-the-plugin",
    "title": "Plugins",
    "section": "How to install the plugin",
    "text": "How to install the plugin\nOnce the plugin is tested (both standalone and when loaded from an agent) it should be installed in the MADS tree. Remember that the command mads -i shows where plugins are expected to be installed (usually, /usr/local/lib). To install:\ncmake --install build\nThe you can launch it as agent with:\nmads source my_source.plugin\nAnd when you are satisfield with the result, you can make it a service as explained here."
  },
  {
    "objectID": "guides/containerized.html",
    "href": "guides/containerized.html",
    "title": "Containerized MADS",
    "section": "",
    "text": "Setting up a MADS network requires a minimum of a broker, a MongoDB server, and the logger agent. This guide explains the easiest and more portable solution to have them up and running in minuts in a Docker environment."
  },
  {
    "objectID": "guides/containerized.html#step-1.-clone-the-repo",
    "href": "guides/containerized.html#step-1.-clone-the-repo",
    "title": "Containerized MADS",
    "section": "Step 1. Clone the repo",
    "text": "Step 1. Clone the repo\nAll you need is in the MADS_container repository. You can clone it with the following command:\ngit clone --depth 1 https://github.com/MADS-NET/MADS_container.git"
  },
  {
    "objectID": "guides/containerized.html#step-2.-run-the-containers",
    "href": "guides/containerized.html#step-2.-run-the-containers",
    "title": "Containerized MADS",
    "section": "Step 2. Run the containers",
    "text": "Step 2. Run the containers\nYou can now run the containers with the following command:\ndocker compose up -d\nThis starts the three containerized processes: MogoDB, the broker, and the logger agent.\n\n\n\n\n\n\nNote\n\n\n\nYou can stop the containers at any time with the command docker compose down.\n\n\nNow the broker and the database are also accessible as if they were processes running on your host machine."
  },
  {
    "objectID": "guides/containerized.html#update-images",
    "href": "guides/containerized.html#update-images",
    "title": "Containerized MADS",
    "section": "Update images",
    "text": "Update images\nTo update the images to the latest version, do:\ndocker compose pull\nfrom project root (i.e. the same folder containing compose.yml)."
  },
  {
    "objectID": "guides/rpio.html",
    "href": "guides/rpio.html",
    "title": "Raspberry Pi IO",
    "section": "",
    "text": "Raspberry Pi boards have a 40-pin GPIO header that can provide useful input-output to switches, relais, LEDs and similar digital I/O devices. The libgpiod library allows direct access to all GPIO pins, which can be set as outputs or inputs. In the latter case, pins can be read synchronously (polling) or asynchronously (on events, i.e. whenever there is a change of state).\nThe rpio_plugin provides a way for interacting with GPIO pins through MADS messages."
  },
  {
    "objectID": "guides/rpio.html#requirements",
    "href": "guides/rpio.html#requirements",
    "title": "Raspberry Pi IO",
    "section": "Requirements",
    "text": "Requirements\nFirst of all, the plugin is designed for the Raspberry Pi. It might work (but it has not been tested) on any Linux system where the libgpiod library is available and that has a GPIO chip and header.\nThe library libgpiod can be installed with sudo apt install libgpiod-dev.\n\n\n\n\n\n\nImportant\n\n\n\nNote that there are two incompatible versions of libgpiod currently diffused: version 1.6.x and version 2.x (aka libgpiod2). At the time of writing this guide, RaspbianOS only comes with the version 1.6 and version 2 is not yet available.\nThe rpio_plugin is designed to build with version 1.6.x and it won’t compile on systems that have the version 2 installed."
  },
  {
    "objectID": "guides/rpio.html#compilation",
    "href": "guides/rpio.html#compilation",
    "title": "Raspberry Pi IO",
    "section": "Compilation",
    "text": "Compilation\nTo obtain the plugin proceed as usual: clone it, compile, and install:\ngit clone -d 1 https://github.com/MADS-NET/rpio_plugin.git\ncd rpio_plugin\ncmake -Bbuild\ncmake --build build -j5\n[sudo] cmake --install build # use sudo if needed\nThis produces and installs two different plugins:\n\nrpio_in.plugin, which is used to read pins values and to publish them on the MADS network;\nrpio_out.plugin, which is used to set pin levels upon receiving the proper JSON command from the MADS network.\n\nRemember that the install command copies these plugins to the MADS library directory, i.e. $(mads -p)/usr/local/lib (if that is outside your home folder, you have to use sudo)."
  },
  {
    "objectID": "guides/rpio.html#for-setting-pin-values",
    "href": "guides/rpio.html#for-setting-pin-values",
    "title": "Raspberry Pi IO",
    "section": "For setting pin values",
    "text": "For setting pin values\nFirst of all, add a proper configuration to mads.ini:\n[rpio_out]\nsub_topic = [\"gpio\"]\nchip_path = \"/dev/gpiochip0\"\nwhere chip_path is the device path of the GPIO device, typically /dev/gpiochip0 on a Raspberry Pi, but it might be different on other device. Check for the proper device with gpiodetect and gpioinfo shell commands.\nThen, the agent will wait for messages published on the topic gpio with a JSON like the following:\n{\n  \"pins\": {\n    \"10\": 1,\n    \"12\": 0\n  }\n}\nwhich will set pin 10 to HIGH and pin 12 to LOW, leaving any other pin unchanged."
  },
  {
    "objectID": "guides/rpio.html#for-reading-pin-values",
    "href": "guides/rpio.html#for-reading-pin-values",
    "title": "Raspberry Pi IO",
    "section": "For reading pin values",
    "text": "For reading pin values\nReading pins is a tad more complicated and can be performed in two different ways.\n\nSynchronous read\nThis means reading pin values immediately or — since the agent runs in a loop — repeatedly at a given time step. The mads.ini configuration is something like:\n[rpio_in]\nchip_path = \"/dev/gpiochip0\"\npub_topic = \"gpio\"\noffsets = [5, 15, 10, 12]\npulldown = true\nevent_mode = \"none\"\nperiod = 500          # in milliseconds\nThis will publish a message with the observed values for pins 5, 15, 10, and 12 every 500 milliseconds, with possibly repeated values (when there is no level change). Use pulldown = true if you want floating pins to be forced low, or pulldown = false to be forced high.\n\n\nAsynchronous read\nSynchronous read is fine if you want to log a time-sequence of pin values, especially when they change frequently. But if you want to read the value of a pin connected to a device like a switch or a push button, that would uselessly flood the network with repeated messages.\nIn these cases, an asynchronous read is much more preferable. This works by waiting for level change and only publishing a message when it happens. The proper mads.ini section is:\n[rpio_in]\nchip_path = \"/dev/gpiochip0\"\npub_topic = \"gpio\"\noffsets = [5, 15, 10, 12]\npulldown = true        # as explained above\nevent_mode = \"rising\"  # options: none, rising, falling, both\nperiod = 500           # in milliseconds\npolling_timeout = 100  # in milliseconds\nThis will wait for a transition from low to high on any of the selected pins; when (and only when!) a transition is detected, it will publish the corresponding message. The period setting means that it won’t publish any message more often that 500 ms; the polling_timeout indicates how long the process wait for a level change before returning a no-change condition, which corresponds to no message being sent and a retry condition in the plugin loop. Making that timeout shorted results in a plugin that is more responsive to signals (e.g. CTRL-C).\n\n\n\n\n\n\nTip\n\n\n\nIt is currently not possible to have the same agent reading different pins in different ways or with different event_modes. If you really find yourself in that condition, you shall run different agents loading the same rpio_in.plugin with different names, and have different sections in the mads.ini file. For example:\n[rpio_in_sync]\nchip_path = \"/dev/gpiochip0\"\npub_topic = \"gpio\"\noffsets = [5, 15]\npulldown = true        # as explained above\nevent_mode = \"none\"    # options: none, rising, falling, both\nperiod = 100           # in milliseconds\n\n[rpio_in_async]\nchip_path = \"/dev/gpiochip0\"\npub_topic = \"gpio\"\noffsets = [10, 12]\npulldown = true        # as explained above\nevent_mode = \"rising\"  # options: none, rising, falling, both\nperiod = 500           # in milliseconds\npolling_timeout = 100  # in milliseconds\nand then launch two agents with different names. In the first terminal run the synchronous agent, reading from pins 5 and 15 every 100 milliseconds:\nmads source rpio_in.plugin -n rpio_in_sync\nOn another terminal run the asynchronous agent, reading only rising level changes on pins 10 and 12:\nmads source rpio_in.plugin -n rpio_in_async"
  },
  {
    "objectID": "guides/python_agent.html",
    "href": "guides/python_agent.html",
    "title": "Python Agent",
    "section": "",
    "text": "The Python3 MADS agent is available on https://github.com/MADS-net/python_agent.\n\n\nYou need to have python3 and python3-dev installed, or Python3 on Windows.\nAlso, you need to have installed the latest MADS version and the proper build toolkit:\n\non UNIX, this means cmake, clang, git\non Windows, this means Visual Studio 2022 (community edition is fine), git and cmake.\n\nThen proceed as follows depending on your platform.\n\n\npython3 -m venv .venv\nsource .venv/bin/activate\npip install numpy\n# also install other necessary Python libs\n\ncmake -Bbuild -DCMAKE_INSTALL_PREFIX=\"$(mads -p)\"\ncmake --build build -j6\nsudo cmake --install build\nThe above is tested on MacOS and Ubuntu 22.04.\n\n\n\nRun the following from project root:\npython -m venv .venv\n.venv\\Scripts\\activate\npip install numpy\n# also install other necessary Python libs\nThen:\ncmake -Bbuild -DCMAKE_INSTALL_PREFIX=\"$(mads -p)\"\ncmake --build build --config Release\nsudo cmake --install build\n\n\n\n\n\n\nEnable sudo on Windows\n\n\n\nFor sudo to work on Windows, you need to enable it on Settings &gt; System &gt; For Developers and set Enable sudo to On.\n\n\n\n\n\n\nThe new agent is installed as mads-python, so you can just type mads python -h (or mads-python -h on Windows) to know more:\n&gt; mads python -h\npython ver. 1.2.6\n\nUsage:\n  python [OPTION...]\n\n  -p, --period arg         Sampling period (default 100 ms)\n  -m, --module arg         Python module to load\n  -n, --name arg           Agent name (default to 'python')\n  -i, --agent-id arg       Agent ID to be added to JSON frames\n  -s, --settings arg       Settings file path/URI\n  -S, --save-settings arg  Save settings to ini file\n  -v, --version            Print version\n  -h, --help               Print usage\nTypically, to launch an agent named python_source, which gets its settings from a python_source section in mads.ini, and uses the Python module named source defined in the source.py file and that runs every 100 ms, the command is:\nmads python -n python_source -m source -p100\nwhere:\n\n-n python_source sets the agent name to python_source, and gets its settings from the same section in the mads.ini file\n-m source sets the Python module to source.py, which is searched for in the Python modules search paths, see below\n-p100 sets the sampling period to 100 ms\n\n\n\n\nThe Python modules are searched for in the following folders:\n\n./python\n./scripts\n../python\n../scripts\n../../python\n../../scripts\nINSTALL_PREFIX + /python\nINSTALL_PREFIX + /scripts\n\nplus any path listed in the mads.ini file under the search_path key (an array or a single string).\n\n\n\nThe following fields are typically used:\n[python_source]\nperiod = 200\nvenv = \"/path/to/.venv\"\npython_module = \"my_source\"\nsearch_paths = [\"/path/to/python/folder\"\n\n\n\n\n\n\nWarning\n\n\n\nThe section name must match the -m option argument when you launch the agent, so in the case aboxe you must use -m python_source.\n\n\nDuring development, you typically run the plugin interactively and using a python module that is under your home folder. In these conditions, you probably want to set the module name on the command line, such as mads python -n python_source -m my_module. This means that you must have the file my_module.py in the python or scripts subfolder of your current working directory.\nDuring deployment, you want to transform the agent in a service, so that you rely on the module to be loaded according to the  mads.ini file (from the python_module key), and the module is expected to be placed in &lt;INSTALL_PREFIX&gt;/python/my_module.py. Since INSTALL_PREFIX is usually /usr/local, this means that the file should be in /usr/local/python/my_module.py. Then you create a service as documented here.\n\n\n\nPython modules can be of type source, filter, or sink. The module type is defined by setting a top level variable like this, typically at the beginning of the script, just after the various imports:\nagent_type = \"sink\"\nAll the modules must implement a setup() function, which is expected to use the dictionary available in the module variable params (a dictionary) to do initial setup (opening ports or files, etc.)\nSource modules must implement a get_output() function, that produces the JSON string that will be published.\nFilter modules must implement a process() function, that is supposed to operate on the last received data dictionary (available as data, a module variable) and produce a JSON string that will be published.\nSink modules must implement a deal_with_data() function, that operates on the data dictionary, a module variable."
  },
  {
    "objectID": "guides/python_agent.html#installing",
    "href": "guides/python_agent.html#installing",
    "title": "Python Agent",
    "section": "",
    "text": "You need to have python3 and python3-dev installed, or Python3 on Windows.\nAlso, you need to have installed the latest MADS version and the proper build toolkit:\n\non UNIX, this means cmake, clang, git\non Windows, this means Visual Studio 2022 (community edition is fine), git and cmake.\n\nThen proceed as follows depending on your platform.\n\n\npython3 -m venv .venv\nsource .venv/bin/activate\npip install numpy\n# also install other necessary Python libs\n\ncmake -Bbuild -DCMAKE_INSTALL_PREFIX=\"$(mads -p)\"\ncmake --build build -j6\nsudo cmake --install build\nThe above is tested on MacOS and Ubuntu 22.04.\n\n\n\nRun the following from project root:\npython -m venv .venv\n.venv\\Scripts\\activate\npip install numpy\n# also install other necessary Python libs\nThen:\ncmake -Bbuild -DCMAKE_INSTALL_PREFIX=\"$(mads -p)\"\ncmake --build build --config Release\nsudo cmake --install build\n\n\n\n\n\n\nEnable sudo on Windows\n\n\n\nFor sudo to work on Windows, you need to enable it on Settings &gt; System &gt; For Developers and set Enable sudo to On."
  },
  {
    "objectID": "guides/python_agent.html#executing",
    "href": "guides/python_agent.html#executing",
    "title": "Python Agent",
    "section": "",
    "text": "The new agent is installed as mads-python, so you can just type mads python -h (or mads-python -h on Windows) to know more:\n&gt; mads python -h\npython ver. 1.2.6\n\nUsage:\n  python [OPTION...]\n\n  -p, --period arg         Sampling period (default 100 ms)\n  -m, --module arg         Python module to load\n  -n, --name arg           Agent name (default to 'python')\n  -i, --agent-id arg       Agent ID to be added to JSON frames\n  -s, --settings arg       Settings file path/URI\n  -S, --save-settings arg  Save settings to ini file\n  -v, --version            Print version\n  -h, --help               Print usage\nTypically, to launch an agent named python_source, which gets its settings from a python_source section in mads.ini, and uses the Python module named source defined in the source.py file and that runs every 100 ms, the command is:\nmads python -n python_source -m source -p100\nwhere:\n\n-n python_source sets the agent name to python_source, and gets its settings from the same section in the mads.ini file\n-m source sets the Python module to source.py, which is searched for in the Python modules search paths, see below\n-p100 sets the sampling period to 100 ms"
  },
  {
    "objectID": "guides/python_agent.html#python-modules-search-paths",
    "href": "guides/python_agent.html#python-modules-search-paths",
    "title": "Python Agent",
    "section": "",
    "text": "The Python modules are searched for in the following folders:\n\n./python\n./scripts\n../python\n../scripts\n../../python\n../../scripts\nINSTALL_PREFIX + /python\nINSTALL_PREFIX + /scripts\n\nplus any path listed in the mads.ini file under the search_path key (an array or a single string)."
  },
  {
    "objectID": "guides/python_agent.html#the-mads.ini-section",
    "href": "guides/python_agent.html#the-mads.ini-section",
    "title": "Python Agent",
    "section": "",
    "text": "The following fields are typically used:\n[python_source]\nperiod = 200\nvenv = \"/path/to/.venv\"\npython_module = \"my_source\"\nsearch_paths = [\"/path/to/python/folder\"\n\n\n\n\n\n\nWarning\n\n\n\nThe section name must match the -m option argument when you launch the agent, so in the case aboxe you must use -m python_source.\n\n\nDuring development, you typically run the plugin interactively and using a python module that is under your home folder. In these conditions, you probably want to set the module name on the command line, such as mads python -n python_source -m my_module. This means that you must have the file my_module.py in the python or scripts subfolder of your current working directory.\nDuring deployment, you want to transform the agent in a service, so that you rely on the module to be loaded according to the  mads.ini file (from the python_module key), and the module is expected to be placed in &lt;INSTALL_PREFIX&gt;/python/my_module.py. Since INSTALL_PREFIX is usually /usr/local, this means that the file should be in /usr/local/python/my_module.py. Then you create a service as documented here."
  },
  {
    "objectID": "guides/python_agent.html#module-types",
    "href": "guides/python_agent.html#module-types",
    "title": "Python Agent",
    "section": "",
    "text": "Python modules can be of type source, filter, or sink. The module type is defined by setting a top level variable like this, typically at the beginning of the script, just after the various imports:\nagent_type = \"sink\"\nAll the modules must implement a setup() function, which is expected to use the dictionary available in the module variable params (a dictionary) to do initial setup (opening ports or files, etc.)\nSource modules must implement a get_output() function, that produces the JSON string that will be published.\nFilter modules must implement a process() function, that is supposed to operate on the last received data dictionary (available as data, a module variable) and produce a JSON string that will be published.\nSink modules must implement a deal_with_data() function, that operates on the data dictionary, a module variable."
  },
  {
    "objectID": "guides/interaction.html",
    "href": "guides/interaction.html",
    "title": "Interacting with MADS",
    "section": "",
    "text": "It is possible to directly interact with a MADS network by sending one-shot JSON messages to the MADS broker. This can be done in three different ways:\n\nby sending a single JSON payload with customized content, often useful for debugging purpose\nby sending special control commands, allowing to pause or resume the MongoDB logging or to restart all agents, thus forcing the re-load of the configuration files\nby using a Terminal User Interface (TUI), which provides a more user-friendly way to interact with MADS, allowing to send control commands and custom messages"
  },
  {
    "objectID": "guides/interaction.html#using-mads-bridge",
    "href": "guides/interaction.html#using-mads-bridge",
    "title": "Interacting with MADS",
    "section": "Using mads bridge",
    "text": "Using mads bridge\nThis command takes a JSON messages and routes it to the MADS network. If the message is not a valid JSON, nothing gets published. The command can be used one-shot by reading the massage on the command line with the -m option:\nmads bridge -t test_topic -m '{\"key\": \"value\"}'\nThis publishes the message {\"key\": \"value\"} to the topic test_topic and returns immediately.\n\n\n\n\n\n\n\nImportant\n\n\n\nRemember: if the broker runs on another machine, you need to specify its settings address with the -s option (see this guide).\n\n\nAlternatively — if the -m option is not provided — the message can be read from the standard input. This can be done either interactively, or by piping to this command from another language. Either case, the command reads a single message terminated by the new line character \\n, publishes it to the specified topic, and then waits for another message. The loop stops when a literal exit\\n is read.\nAs an option, a message can be sent to a different topic by prependint the topic name followed by a colon : to the JSON message. For example, the message special_topic:{\"key\": \"value\"}\\n is sent to the topic special_topic instead of the default test_topic.\n\n\n\n\n\n\nImportant\n\n\n\nSince the newline character \\n is used to terminate the message, the JSON payload cannot contain newline characters.\n\n\nAs an example, the following is a Python script that uses the mads bridge command to send 10 messages in a sequence:\n# open the bridge as a subprocess\nif len(sys.argv) &gt; 1:\n  process = subprocess.Popen('mads-broker', stdin=subprocess.PIPE)\nelse:\n  print(\"Usage: python3 stress.py topic\")\n  sys.exit(1)\n\ni = 0\n# Write to the subprocess' standard input\nwhile i &lt; 10:\n  json_data = {\n    \"script\": __file__,\n    \"id\": i,\n    \"date\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n  }\n  process.stdin.write(json.dumps(json_data).encode())\n  process.stdin.write(b'\\n')  # newline character\n  process.stdin.flush()       # flush the buffer\n  time.sleep(0.2)\n  i += 1\n\n# Close the subprocess' by sending the magic word \"exit\"\nprocess.stdin.write(b'exit\\n')\nprocess.stdin.close()\nprocess.wait()\n\n\n\n\n\n\nWhen to use mads bridge vs mads source\n\n\n\nThe interactive mode of mads bridge is actually a legacy functionality that predates the plugin loaders commands (see next section). Those are now preferred and provide more flexibility and better integration with the MADS ecosystem. However, mads bridge remains available for backward compatibility and for quick debugging tasks, especially for sending a single message with the -m option."
  },
  {
    "objectID": "guides/interaction.html#using-plugin-loaders",
    "href": "guides/interaction.html#using-plugin-loaders",
    "title": "Interacting with MADS",
    "section": "Using plugin loaders",
    "text": "Using plugin loaders\nThe plugin loaders commands (mads source, mads filter, and mads sink) are the agents that are typically used to load a source plugin. However, if no plugin is given as argument, they acts on STDIN and STDOUT to route messages to and from the MADS network.\nIf no plugin is provided on the command line:\n\nmads source reads messages from STDIN and publishes them to the MADS broker\nmads sink subscribes to a topic on the MADS broker and writes received messages to STDOUT\nmads filter subscribes to a topic on the MADS broker, and for each received message, it writes it to STDOUT and reads a message from STDIN to publish it back to the MADS broker\n\nWith these three commands, by using the pipe operations as in the above example, it is possible to create agents in arguably any programming language, including shell scripts or direct shell interaction, as in the following clip:\n\n\n\n\n\n\n\nHow mads filter works\n\n\n\nNote that the mads filter expect to receive a message from the MADS network, which it writes to STDOUT, and then it waits for a message from STDIN to publish it back to the MADS network. This means that if you use mads filter in a pipe, you need to ensure that the preceding command in the pipe is capable of providing input to mads filter. If the preceding command does not provide input, mads filter will block indefinitely waiting for input. The same holds if you are using it interactively: you need to provide a message to mads filter after it receives one from the MADS network.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nInteracting via pipes is less efficient than using a dedicated plugin, as each message is handled by a separate process. This can be a bottleneck when dealing with high-frequency messages.\nFor this reason, writing dedicated plugins is the proper way to extend MADS for production use cases."
  },
  {
    "objectID": "guides/OTA_plugins.html",
    "href": "guides/OTA_plugins.html",
    "title": "OTA Plugins",
    "section": "",
    "text": "Suppose that you have a MADS network made by a relatively large number of devices, each running one or more agents. You want to update the plugins loaded by the agents. If you have only a few devices (say 2–3), you can manually copy the plugin files to each device. But if you have many devices, this is not practical and it is also error prone, because you need to keep track of which devices have been updated and which haven’t.\nThis use case is where the idea of being able to load plugins OTA comes from. The broker can provide the plugin files to the agents, which can then load them dynamically. This allows you to update the plugins without having to manually copy the files to each device: only the broker needs to have the plugin files, and the agents will load them automatically. There is only one copy of each plugin, and no risk of mismatching versions."
  },
  {
    "objectID": "guides/OTA_plugins.html#plugin-and-agent-names",
    "href": "guides/OTA_plugins.html#plugin-and-agent-names",
    "title": "OTA Plugins",
    "section": "Plugin and agent names",
    "text": "Plugin and agent names\nIn MADS, there are three agents able to load plugins: source, filter, and sink. As for any agent, the INI section to be loaded is defined by the agent name. In turn, the latter is defined as:\n\nthe name of the agent executable for monolithic plugins\nthe name of the plugin for source, filter, and sink\n\n\n\n\n\n\n\nNote\n\n\n\nIn reality, there is also the worker agent (see here), which behaves as a filter agent but it is designed for a 1 dealer / n worker scenario for parallel computing, where a single dealer agent dispatches a list of computations to a number of identical workers in a round-robin fashion. The agent name for a worker is mandatory (no default).\n\n\nAlso, note that source, filter, and sink agents can be called without a plugin: in this case, they run as general-purpose agents that deal with input and output data (as valid JSON strings) via pipes. When this happen, the agent names are publish for the source agent, bridge for the filter agent, and feedback for the sink agent.\nThe name of an agent can be always be overridden by the -n command line option, which allows to specify a custom name for the agent. This is useful, for example, when you want to run multiple instances of the same agent with different settings.\nNow, since the OTA loading of the plugin happens after the agent has loaded its settings, the agent name must be specified with the -n CLI option, otherwise would simply launch as general purpose agent with default names.\nFor example, if the mads.ini file contains the [my_datasource] section as above, the agent must be launched as:\nmads source -s tcp://mads-broker.local:9093 -n my_datasource"
  },
  {
    "objectID": "guides/OTA_plugins.html#dealing-with-architectures",
    "href": "guides/OTA_plugins.html#dealing-with-architectures",
    "title": "OTA Plugins",
    "section": "Dealing with architectures",
    "text": "Dealing with architectures\nWhen the plugin is provided as an attachment, the broker will send a copy of the file to the agent, which will save it to a temporary folder and load it dynamically. This means that the plugin must be compatible with the architecture of the device running the agent.\nNow suppose that we want to run the same plugin on different devices, some of which are ARM-based and some are x86-based. If the plugin is compiled for a specific architecture, it will not work on the other architecture.\nThe solution follows these steps:\n\ncompile two plugin versions, one for each architecture, and copy both files on the broker filesystem. Call them, for example, my_datasource_arm.plugin and my_datasource_x86.plugin\nin the mads.ini file, define two sections, one for each architecture with different names:\n[my_datasource_arm]\nattachment = \"/path/to/my_datasource_arm.plugin\"\n[my_datasource_x86]\nattachment = \"/path/to/my_datasource_x86.plugin\"\nwhen launching the agent, specify the correct section name with the -n option, depending on the architecture of the device running the agent:\nmads source -s tcp://mads-broker.local:9093 -n my_datasource_arm\n\nNote that, when compiling a plugin, the CMakeLists.txt file in the plugin project has an option to append an architecture suffix to the generated plugin file: if you configure the project as:\ncmake -Bbuild -DPLUGIN_SUFFIX=arm -DCMAKE_INSTALL_PREFIX=$(mads -p)\nthen the plugin will be compiled as my_datasource_arm.plugin (assuming the plugin name is my_datasource). Of course, versions for non-native architectures must be cross-compiled or compiled in a virtual machine or on the target device itself."
  },
  {
    "objectID": "guides/OTA_plugins.html#command-line-vs.-attachment",
    "href": "guides/OTA_plugins.html#command-line-vs.-attachment",
    "title": "OTA Plugins",
    "section": "Command line vs. attachment",
    "text": "Command line vs. attachment\nNote that command line options always override the settings in the mads.ini file, so if you also specify the plugin name, the broker attachment will be ignored. For example, the following command will not load the plugin from the broker, but will use the one specified on the command line (on the local filesystem):\nmads source -s tcp://mads-broker.local:9093 -n my_datasource my_datasource.plugin"
  }
]